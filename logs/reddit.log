2025-05-15 10:10:20,483 [INFO] Starting Reddit scraping...
2025-05-15 10:10:32,453 [INFO] Successfully stored 128 Reddit posts in the database
2025-05-15 10:25:14,122 [INFO] Starting Reddit scraping...
2025-05-15 10:25:14,122 [INFO] Starting Reddit scraping...
2025-05-15 10:25:24,051 [INFO] Successfully stored 127 Reddit posts in the database
2025-05-15 10:25:24,051 [INFO] Successfully stored 127 Reddit posts in the database
2025-05-15 10:26:45,993 [INFO] Starting Reddit scraping...
2025-05-15 10:26:56,943 [ERROR] Error during Reddit scraping: ON CONFLICT DO UPDATE command cannot affect row a second time
HINT:  Ensure that no rows proposed for insertion within the same command have duplicate constrained values.

2025-05-15 10:26:56,951 [ERROR] Detailed error:
Traceback (most recent call last):
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\src\scheduler\jobs\reddit_scraper.py", line 153, in scrape_reddit
    execute_values(cur, insert_query, values)
    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\psycopg2\extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^
psycopg2.errors.CardinalityViolation: ON CONFLICT DO UPDATE command cannot affect row a second time
HINT:  Ensure that no rows proposed for insertion within the same command have duplicate constrained values.

2025-05-15 10:28:01,051 [INFO] Starting Reddit scraping...
2025-05-15 10:28:10,819 [ERROR] Error during Reddit scraping: ON CONFLICT DO UPDATE command cannot affect row a second time
HINT:  Ensure that no rows proposed for insertion within the same command have duplicate constrained values.

2025-05-15 10:28:10,819 [ERROR] Detailed error:
Traceback (most recent call last):
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\src\scheduler\jobs\reddit_scraper.py", line 153, in scrape_reddit
    execute_values(cur, insert_query, values)
    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\psycopg2\extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^
psycopg2.errors.CardinalityViolation: ON CONFLICT DO UPDATE command cannot affect row a second time
HINT:  Ensure that no rows proposed for insertion within the same command have duplicate constrained values.

2025-05-15 10:32:13,701 [INFO] Starting Reddit scraping...
2025-05-15 10:32:13,717 [INFO] Successfully connected to Reddit API
2025-05-15 10:32:13,717 [INFO] Scraping subreddit: r/all
2025-05-15 10:32:15,532 [INFO] Found 3 posts in r/all
2025-05-15 10:32:15,533 [INFO] Scraping subreddit: r/popular
2025-05-15 10:32:16,896 [INFO] Found 6 posts in r/popular
2025-05-15 10:32:16,896 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 10:32:17,835 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 10:32:17,835 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 10:32:20,036 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 10:32:20,037 [INFO] Found 127 unique posts out of 130 total posts
2025-05-15 10:32:23,054 [ERROR] Error during Reddit scraping: ON CONFLICT DO UPDATE command cannot affect row a second time
HINT:  Ensure that no rows proposed for insertion within the same command have duplicate constrained values.

2025-05-15 10:32:23,055 [ERROR] Detailed error:
Traceback (most recent call last):
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\src\scheduler\jobs\reddit_scraper.py", line 166, in scrape_reddit
    execute_values(cur, insert_query, values)
    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\psycopg2\extras.py", line 1299, in execute_values
    cur.execute(b''.join(parts))
    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^
psycopg2.errors.CardinalityViolation: ON CONFLICT DO UPDATE command cannot affect row a second time
HINT:  Ensure that no rows proposed for insertion within the same command have duplicate constrained values.

2025-05-15 10:33:45,232 [INFO] Starting Reddit scraping...
2025-05-15 10:33:45,233 [INFO] Successfully connected to Reddit API
2025-05-15 10:33:45,233 [INFO] Scraping subreddit: r/all
2025-05-15 10:33:47,112 [INFO] Found 3 posts in r/all
2025-05-15 10:33:47,112 [INFO] Scraping subreddit: r/popular
2025-05-15 10:33:48,454 [INFO] Found 6 posts in r/popular
2025-05-15 10:33:48,454 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 10:33:49,462 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 10:33:49,462 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 10:33:51,932 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 10:33:51,932 [INFO] Found 127 unique posts out of 130 total posts
2025-05-15 10:33:54,191 [ERROR] Error processing batch: ON CONFLICT DO UPDATE command cannot affect row a second time
HINT:  Ensure that no rows proposed for insertion within the same command have duplicate constrained values.

2025-05-15 10:33:54,790 [ERROR] Error processing batch: relation "reddit_data" does not exist
LINE 2:                             INSERT INTO reddit_data (
                                                ^

2025-05-15 10:33:55,387 [ERROR] Error processing batch: relation "reddit_data" does not exist
LINE 2:                             INSERT INTO reddit_data (
                                                ^

2025-05-15 10:33:55,989 [ERROR] Error processing batch: relation "reddit_data" does not exist
LINE 2:                             INSERT INTO reddit_data (
                                                ^

2025-05-15 10:33:56,587 [ERROR] Error processing batch: relation "reddit_data" does not exist
LINE 2:                             INSERT INTO reddit_data (
                                                ^

2025-05-15 10:33:57,190 [ERROR] Error processing batch: relation "reddit_data" does not exist
LINE 2:                             INSERT INTO reddit_data (
                                                ^

2025-05-15 10:33:57,789 [ERROR] Error processing batch: relation "reddit_data" does not exist
LINE 2:                             INSERT INTO reddit_data (
                                                ^

2025-05-15 10:33:58,420 [ERROR] Error processing batch: relation "reddit_data" does not exist
LINE 2:                             INSERT INTO reddit_data (
                                                ^

2025-05-15 10:33:59,069 [ERROR] Error processing batch: relation "reddit_data" does not exist
LINE 2:                             INSERT INTO reddit_data (
                                                ^

2025-05-15 10:33:59,667 [ERROR] Error processing batch: relation "reddit_data" does not exist
LINE 2:                             INSERT INTO reddit_data (
                                                ^

2025-05-15 10:34:00,265 [ERROR] Error processing batch: relation "reddit_data" does not exist
LINE 2:                             INSERT INTO reddit_data (
                                                ^

2025-05-15 10:34:00,867 [ERROR] Error processing batch: relation "reddit_data" does not exist
LINE 2:                             INSERT INTO reddit_data (
                                                ^

2025-05-15 10:34:01,464 [ERROR] Error processing batch: relation "reddit_data" does not exist
LINE 2:                             INSERT INTO reddit_data (
                                                ^

2025-05-15 10:34:01,662 [INFO] Successfully processed 127 Reddit posts (0 inserted, 0 updated)
2025-05-15 10:34:47,400 [INFO] Starting Reddit scraping...
2025-05-15 10:34:47,401 [INFO] Successfully connected to Reddit API
2025-05-15 10:34:47,401 [INFO] Scraping subreddit: r/all
2025-05-15 10:34:49,629 [INFO] Found 3 posts in r/all
2025-05-15 10:34:49,629 [INFO] Scraping subreddit: r/popular
2025-05-15 10:34:51,422 [INFO] Found 6 posts in r/popular
2025-05-15 10:34:51,422 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 10:34:52,327 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 10:34:52,327 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 10:34:54,791 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 10:34:54,792 [INFO] Found 127 unique posts out of 130 total posts
2025-05-15 10:34:57,445 [ERROR] Error processing batch: ON CONFLICT DO UPDATE command cannot affect row a second time
HINT:  Ensure that no rows proposed for insertion within the same command have duplicate constrained values.

2025-05-15 10:35:05,346 [INFO] Successfully processed 117 Reddit posts (0 inserted, 0 updated)
2025-05-15 10:35:55,688 [INFO] Starting Reddit scraping...
2025-05-15 10:35:55,689 [INFO] Successfully connected to Reddit API
2025-05-15 10:35:55,690 [INFO] Scraping subreddit: r/all
2025-05-15 10:35:57,431 [INFO] Found 3 posts in r/all
2025-05-15 10:35:57,431 [INFO] Scraping subreddit: r/popular
2025-05-15 10:35:58,707 [INFO] Found 6 posts in r/popular
2025-05-15 10:35:58,708 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 10:35:59,651 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 10:35:59,651 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 10:36:02,345 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 10:36:02,345 [INFO] Found 127 unique posts out of 130 total posts
2025-05-15 10:37:21,498 [INFO] Successfully processed 127 Reddit posts (8 inserted, 119 updated)
2025-05-15 10:40:02,419 [INFO] Starting Reddit scraping...
2025-05-15 10:40:02,420 [INFO] Successfully connected to Reddit API
2025-05-15 10:40:02,420 [INFO] Scraping subreddit: r/all
2025-05-15 10:40:04,554 [INFO] Found 3 posts in r/all
2025-05-15 10:40:04,554 [INFO] Scraping subreddit: r/popular
2025-05-15 10:40:05,864 [INFO] Found 6 posts in r/popular
2025-05-15 10:40:05,865 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 10:40:06,721 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 10:40:06,721 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 10:40:09,125 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 10:40:09,126 [INFO] Found 127 unique posts out of 130 total posts
2025-05-15 10:40:48,756 [INFO] Starting Reddit scraping...
2025-05-15 10:40:48,756 [INFO] Starting Reddit scraping...
2025-05-15 10:40:48,756 [INFO] Starting Reddit scraping...
2025-05-15 10:40:48,757 [INFO] Successfully connected to Reddit API
2025-05-15 10:40:48,757 [INFO] Successfully connected to Reddit API
2025-05-15 10:40:48,757 [INFO] Successfully connected to Reddit API
2025-05-15 10:40:48,757 [INFO] Scraping subreddit: r/all
2025-05-15 10:40:48,757 [INFO] Scraping subreddit: r/all
2025-05-15 10:40:48,757 [INFO] Scraping subreddit: r/all
2025-05-15 10:40:50,564 [INFO] Found 3 posts in r/all
2025-05-15 10:40:50,564 [INFO] Found 3 posts in r/all
2025-05-15 10:40:50,564 [INFO] Found 3 posts in r/all
2025-05-15 10:40:50,565 [INFO] Scraping subreddit: r/popular
2025-05-15 10:40:50,565 [INFO] Scraping subreddit: r/popular
2025-05-15 10:40:50,565 [INFO] Scraping subreddit: r/popular
2025-05-15 10:40:51,856 [INFO] Found 6 posts in r/popular
2025-05-15 10:40:51,856 [INFO] Found 6 posts in r/popular
2025-05-15 10:40:51,856 [INFO] Found 6 posts in r/popular
2025-05-15 10:40:51,857 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 10:40:51,857 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 10:40:51,857 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 10:40:52,803 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 10:40:52,803 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 10:40:52,803 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 10:40:52,803 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 10:40:52,803 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 10:40:52,803 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 10:40:55,354 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 10:40:55,354 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 10:40:55,354 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 10:40:55,354 [INFO] Found 127 unique posts out of 130 total posts
2025-05-15 10:40:55,354 [INFO] Found 127 unique posts out of 130 total posts
2025-05-15 10:40:55,354 [INFO] Found 127 unique posts out of 130 total posts
2025-05-15 10:41:28,659 [INFO] Successfully processed 127 Reddit posts (0 inserted, 127 updated)
2025-05-15 10:42:13,772 [INFO] Successfully processed 127 Reddit posts (0 inserted, 127 updated)
2025-05-15 10:42:13,772 [INFO] Successfully processed 127 Reddit posts (0 inserted, 127 updated)
2025-05-15 10:42:13,772 [INFO] Successfully processed 127 Reddit posts (0 inserted, 127 updated)
2025-05-15 10:56:43,752 [INFO] Starting Reddit scraping...
2025-05-15 10:56:43,753 [INFO] Successfully connected to Reddit API
2025-05-15 10:56:43,753 [INFO] Scraping subreddit: r/all
2025-05-15 10:56:45,556 [INFO] Found 3 posts in r/all
2025-05-15 10:56:45,557 [INFO] Scraping subreddit: r/popular
2025-05-15 10:56:47,093 [INFO] Found 6 posts in r/popular
2025-05-15 10:56:47,093 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 10:56:48,314 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 10:56:48,315 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 10:56:50,574 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 10:56:50,575 [INFO] Found 127 unique posts out of 130 total posts
2025-05-15 10:57:53,511 [INFO] Starting Reddit scraping...
2025-05-15 10:57:53,511 [INFO] Starting Reddit scraping...
2025-05-15 10:57:53,511 [INFO] Starting Reddit scraping...
2025-05-15 10:57:53,511 [INFO] Starting Reddit scraping...
2025-05-15 10:57:53,512 [INFO] Successfully connected to Reddit API
2025-05-15 10:57:53,512 [INFO] Successfully connected to Reddit API
2025-05-15 10:57:53,512 [INFO] Successfully connected to Reddit API
2025-05-15 10:57:53,512 [INFO] Successfully connected to Reddit API
2025-05-15 10:57:53,512 [INFO] Scraping subreddit: r/all
2025-05-15 10:57:53,512 [INFO] Scraping subreddit: r/all
2025-05-15 10:57:53,512 [INFO] Scraping subreddit: r/all
2025-05-15 10:57:53,512 [INFO] Scraping subreddit: r/all
2025-05-15 10:57:55,352 [INFO] Found 3 posts in r/all
2025-05-15 10:57:55,352 [INFO] Found 3 posts in r/all
2025-05-15 10:57:55,352 [INFO] Found 3 posts in r/all
2025-05-15 10:57:55,352 [INFO] Found 3 posts in r/all
2025-05-15 10:57:55,353 [INFO] Scraping subreddit: r/popular
2025-05-15 10:57:55,353 [INFO] Scraping subreddit: r/popular
2025-05-15 10:57:55,353 [INFO] Scraping subreddit: r/popular
2025-05-15 10:57:55,353 [INFO] Scraping subreddit: r/popular
2025-05-15 10:57:56,653 [INFO] Found 5 posts in r/popular
2025-05-15 10:57:56,653 [INFO] Found 5 posts in r/popular
2025-05-15 10:57:56,653 [INFO] Found 5 posts in r/popular
2025-05-15 10:57:56,653 [INFO] Found 5 posts in r/popular
2025-05-15 10:57:56,654 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 10:57:56,654 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 10:57:56,654 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 10:57:56,654 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 10:57:57,541 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 10:57:57,541 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 10:57:57,541 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 10:57:57,541 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 10:57:57,542 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 10:57:57,542 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 10:57:57,542 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 10:57:57,542 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 10:58:00,293 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 10:58:00,293 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 10:58:00,293 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 10:58:00,293 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 10:58:00,293 [INFO] Found 126 unique posts out of 129 total posts
2025-05-15 10:58:00,293 [INFO] Found 126 unique posts out of 129 total posts
2025-05-15 10:58:00,293 [INFO] Found 126 unique posts out of 129 total posts
2025-05-15 10:58:00,293 [INFO] Found 126 unique posts out of 129 total posts
2025-05-15 10:58:08,454 [INFO] Successfully processed 127 Reddit posts (1 inserted, 126 updated)
2025-05-15 10:59:17,329 [INFO] Successfully processed 126 Reddit posts (0 inserted, 126 updated)
2025-05-15 10:59:17,329 [INFO] Successfully processed 126 Reddit posts (0 inserted, 126 updated)
2025-05-15 10:59:17,329 [INFO] Successfully processed 126 Reddit posts (0 inserted, 126 updated)
2025-05-15 10:59:17,329 [INFO] Successfully processed 126 Reddit posts (0 inserted, 126 updated)
2025-05-15 11:13:26,458 [INFO] Starting Reddit scraping...
2025-05-15 11:13:26,458 [INFO] Successfully connected to Reddit API
2025-05-15 11:13:26,459 [INFO] Scraping subreddit: r/all
2025-05-15 11:13:28,145 [INFO] Found 3 posts in r/all
2025-05-15 11:13:28,145 [INFO] Scraping subreddit: r/popular
2025-05-15 11:13:29,522 [INFO] Found 5 posts in r/popular
2025-05-15 11:13:29,522 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 11:13:30,598 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 11:13:30,599 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 11:13:33,520 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 11:13:33,521 [INFO] Found 126 unique posts out of 129 total posts
2025-05-15 11:14:50,648 [INFO] Starting Reddit scraping...
2025-05-15 11:14:50,648 [INFO] Starting Reddit scraping...
2025-05-15 11:14:50,648 [INFO] Starting Reddit scraping...
2025-05-15 11:14:50,648 [INFO] Starting Reddit scraping...
2025-05-15 11:14:50,648 [INFO] Starting Reddit scraping...
2025-05-15 11:14:50,649 [INFO] Successfully connected to Reddit API
2025-05-15 11:14:50,649 [INFO] Successfully connected to Reddit API
2025-05-15 11:14:50,649 [INFO] Successfully connected to Reddit API
2025-05-15 11:14:50,649 [INFO] Successfully connected to Reddit API
2025-05-15 11:14:50,649 [INFO] Successfully connected to Reddit API
2025-05-15 11:14:50,649 [INFO] Scraping subreddit: r/all
2025-05-15 11:14:50,649 [INFO] Scraping subreddit: r/all
2025-05-15 11:14:50,649 [INFO] Scraping subreddit: r/all
2025-05-15 11:14:50,649 [INFO] Scraping subreddit: r/all
2025-05-15 11:14:50,649 [INFO] Scraping subreddit: r/all
2025-05-15 11:14:52,283 [INFO] Found 3 posts in r/all
2025-05-15 11:14:52,283 [INFO] Found 3 posts in r/all
2025-05-15 11:14:52,283 [INFO] Found 3 posts in r/all
2025-05-15 11:14:52,283 [INFO] Found 3 posts in r/all
2025-05-15 11:14:52,283 [INFO] Found 3 posts in r/all
2025-05-15 11:14:52,284 [INFO] Scraping subreddit: r/popular
2025-05-15 11:14:52,284 [INFO] Scraping subreddit: r/popular
2025-05-15 11:14:52,284 [INFO] Scraping subreddit: r/popular
2025-05-15 11:14:52,284 [INFO] Scraping subreddit: r/popular
2025-05-15 11:14:52,284 [INFO] Scraping subreddit: r/popular
2025-05-15 11:14:52,583 [INFO] Successfully processed 126 Reddit posts (1 inserted, 125 updated)
2025-05-15 11:14:53,583 [INFO] Found 5 posts in r/popular
2025-05-15 11:14:53,583 [INFO] Found 5 posts in r/popular
2025-05-15 11:14:53,583 [INFO] Found 5 posts in r/popular
2025-05-15 11:14:53,583 [INFO] Found 5 posts in r/popular
2025-05-15 11:14:53,583 [INFO] Found 5 posts in r/popular
2025-05-15 11:14:53,584 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 11:14:53,584 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 11:14:53,584 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 11:14:53,584 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 11:14:53,584 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 11:14:54,559 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 11:14:54,559 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 11:14:54,559 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 11:14:54,559 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 11:14:54,559 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 11:14:54,560 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 11:14:54,560 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 11:14:54,560 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 11:14:54,560 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 11:14:54,560 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 11:14:57,056 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 11:14:57,056 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 11:14:57,056 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 11:14:57,056 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 11:14:57,056 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 11:14:57,057 [INFO] Found 126 unique posts out of 129 total posts
2025-05-15 11:14:57,057 [INFO] Found 126 unique posts out of 129 total posts
2025-05-15 11:14:57,057 [INFO] Found 126 unique posts out of 129 total posts
2025-05-15 11:14:57,057 [INFO] Found 126 unique posts out of 129 total posts
2025-05-15 11:14:57,057 [INFO] Found 126 unique posts out of 129 total posts
2025-05-15 14:12:49,477 [INFO] Starting Reddit scraping...
2025-05-15 14:12:49,678 [INFO] Successfully connected to Reddit API
2025-05-15 14:12:49,678 [INFO] Scraping subreddit: r/all
2025-05-15 14:12:51,524 [INFO] Found 6 posts in r/all
2025-05-15 14:12:51,524 [INFO] Scraping subreddit: r/popular
2025-05-15 14:12:53,158 [INFO] Found 6 posts in r/popular
2025-05-15 14:12:53,159 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 14:12:54,280 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 14:12:54,281 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 14:12:56,961 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 14:12:56,962 [INFO] Found 130 unique posts out of 133 total posts
2025-05-15 14:14:16,068 [INFO] Successfully processed 130 Reddit posts (4 inserted, 126 updated)
2025-05-15 14:29:52,831 [INFO] Starting Reddit scraping...
2025-05-15 14:29:52,832 [INFO] Successfully connected to Reddit API
2025-05-15 14:29:52,833 [INFO] Scraping subreddit: r/all
2025-05-15 14:29:54,524 [INFO] Found 7 posts in r/all
2025-05-15 14:29:54,525 [INFO] Scraping subreddit: r/popular
2025-05-15 14:29:55,955 [INFO] Found 7 posts in r/popular
2025-05-15 14:29:55,956 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 14:29:57,350 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 14:29:57,350 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 14:29:59,769 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 14:29:59,770 [INFO] Found 132 unique posts out of 135 total posts
2025-05-15 14:31:20,911 [INFO] Successfully processed 132 Reddit posts (2 inserted, 130 updated)
2025-05-15 14:46:39,296 [INFO] Starting Reddit scraping...
2025-05-15 14:46:39,296 [INFO] Successfully connected to Reddit API
2025-05-15 14:46:39,297 [INFO] Scraping subreddit: r/all
2025-05-15 14:46:41,420 [INFO] Found 7 posts in r/all
2025-05-15 14:46:41,420 [INFO] Scraping subreddit: r/popular
2025-05-15 14:46:42,636 [INFO] Found 7 posts in r/popular
2025-05-15 14:46:42,636 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 14:46:43,623 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 14:46:43,623 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 14:46:46,307 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 14:46:46,307 [INFO] Found 132 unique posts out of 135 total posts
2025-05-15 14:48:07,058 [INFO] Successfully processed 132 Reddit posts (0 inserted, 132 updated)
2025-05-15 15:03:43,089 [INFO] Starting Reddit scraping...
2025-05-15 15:03:43,089 [INFO] Successfully connected to Reddit API
2025-05-15 15:03:43,090 [INFO] Scraping subreddit: r/all
2025-05-15 15:03:45,098 [INFO] Found 7 posts in r/all
2025-05-15 15:03:45,098 [INFO] Scraping subreddit: r/popular
2025-05-15 15:03:46,453 [INFO] Found 6 posts in r/popular
2025-05-15 15:03:46,454 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 15:03:47,547 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 15:03:47,548 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 15:03:49,636 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 15:03:49,636 [INFO] Found 131 unique posts out of 134 total posts
2025-05-15 15:05:11,212 [INFO] Successfully processed 131 Reddit posts (0 inserted, 131 updated)
2025-05-15 15:32:07,523 [INFO] Starting Reddit scraping...
2025-05-15 15:32:07,524 [INFO] Successfully connected to Reddit API
2025-05-15 15:32:07,524 [INFO] Scraping subreddit: r/all
2025-05-15 15:32:09,364 [INFO] Found 7 posts in r/all
2025-05-15 15:32:09,364 [INFO] Scraping subreddit: r/popular
2025-05-15 15:32:10,673 [INFO] Found 5 posts in r/popular
2025-05-15 15:32:10,674 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 15:32:11,623 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 15:32:11,623 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 15:32:14,463 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 15:32:14,464 [INFO] Found 130 unique posts out of 133 total posts
2025-05-15 15:33:34,785 [INFO] Successfully processed 130 Reddit posts (1 inserted, 129 updated)
2025-05-15 15:48:50,033 [INFO] Starting Reddit scraping...
2025-05-15 15:48:50,034 [INFO] Successfully connected to Reddit API
2025-05-15 15:48:50,034 [INFO] Scraping subreddit: r/all
2025-05-15 15:48:51,612 [INFO] Found 7 posts in r/all
2025-05-15 15:48:51,613 [INFO] Scraping subreddit: r/popular
2025-05-15 15:48:52,910 [INFO] Found 6 posts in r/popular
2025-05-15 15:48:52,910 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 15:48:54,229 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 15:48:54,230 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 15:48:58,625 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 15:48:58,625 [INFO] Found 131 unique posts out of 134 total posts
2025-05-15 15:50:20,347 [INFO] Successfully processed 131 Reddit posts (1 inserted, 130 updated)
2025-05-15 16:05:35,091 [INFO] Starting Reddit scraping...
2025-05-15 16:05:35,092 [INFO] Successfully connected to Reddit API
2025-05-15 16:05:35,092 [INFO] Scraping subreddit: r/all
2025-05-15 16:05:36,836 [INFO] Found 6 posts in r/all
2025-05-15 16:05:36,837 [INFO] Scraping subreddit: r/popular
2025-05-15 16:05:38,392 [INFO] Found 7 posts in r/popular
2025-05-15 16:05:38,393 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 16:05:39,735 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 16:05:39,735 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 16:31:37,586 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 16:31:37,587 [INFO] Found 131 unique posts out of 134 total posts
2025-05-15 16:32:59,875 [INFO] Successfully processed 131 Reddit posts (2 inserted, 129 updated)
2025-05-15 16:48:17,791 [INFO] Starting Reddit scraping...
2025-05-15 16:48:17,792 [INFO] Successfully connected to Reddit API
2025-05-15 16:48:17,792 [INFO] Scraping subreddit: r/all
2025-05-15 16:48:19,308 [INFO] Found 7 posts in r/all
2025-05-15 16:48:19,308 [INFO] Scraping subreddit: r/popular
2025-05-15 16:48:20,569 [INFO] Found 10 posts in r/popular
2025-05-15 16:48:20,569 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 16:48:21,988 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 16:48:21,988 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 16:48:24,777 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 16:48:24,778 [INFO] Found 135 unique posts out of 138 total posts
2025-05-15 16:49:48,756 [INFO] Successfully processed 135 Reddit posts (2 inserted, 133 updated)
2025-05-15 17:05:06,810 [INFO] Starting Reddit scraping...
2025-05-15 17:05:06,811 [INFO] Successfully connected to Reddit API
2025-05-15 17:05:06,811 [INFO] Scraping subreddit: r/all
2025-05-15 17:05:08,671 [INFO] Found 7 posts in r/all
2025-05-15 17:05:08,671 [INFO] Scraping subreddit: r/popular
2025-05-15 17:05:10,339 [INFO] Found 10 posts in r/popular
2025-05-15 17:05:10,340 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 17:05:11,661 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 17:05:11,662 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 17:05:14,184 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 17:05:14,184 [INFO] Found 135 unique posts out of 138 total posts
2025-05-15 17:06:38,172 [INFO] Successfully processed 135 Reddit posts (1 inserted, 134 updated)
2025-05-15 17:18:05,569 [INFO] Starting Reddit scraping...
2025-05-15 17:18:05,807 [INFO] Successfully connected to Reddit API
2025-05-15 17:18:05,808 [INFO] Scraping subreddit: r/all
2025-05-15 17:18:06,131 [ERROR] Error during Reddit scraping: received 401 HTTP response
2025-05-15 17:18:06,132 [ERROR] Detailed error:
Traceback (most recent call last):
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\src\scheduler\jobs\reddit_scraper.py", line 97, in scrape_reddit
    for post in subreddit.hot(limit=post_limit):
                ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 66, in __next__
    self._next_batch()
    ~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 90, in _next_batch
    self._listing = self._reddit.get(self.url, params=self.params)
                    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 731, in get
    return self._objectify_request(method="GET", params=params, path=path)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 514, in _objectify_request
    self.request(
    ~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 963, in request
    return self._core.request(
           ~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 328, in request
    return self._request_with_retries(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<5 lines>...
        url=url,
        ^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 234, in _request_with_retries
    response, saved_exception = self._make_request(
                                ~~~~~~~~~~~~~~~~~~^
        data,
        ^^^^^
    ...<6 lines>...
        url,
        ^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 186, in _make_request
    response = self._rate_limiter.call(
        self._requestor.request,
    ...<8 lines>...
        timeout=timeout,
    )
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\rate_limit.py", line 46, in call
    kwargs["headers"] = set_header_callback()
                        ~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 282, in _set_header_callback
    self._authorizer.refresh()
    ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 378, in refresh
    self._request_token(grant_type="client_credentials", **additional_kwargs)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 155, in _request_token
    response = self._authenticator._post(url=url, **data)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 59, in _post
    raise ResponseException(response)
prawcore.exceptions.ResponseException: received 401 HTTP response
2025-05-15 17:35:08,282 [INFO] Starting Reddit scraping...
2025-05-15 17:35:08,297 [INFO] Successfully connected to Reddit API
2025-05-15 17:35:08,297 [INFO] Scraping subreddit: r/all
2025-05-15 17:35:08,666 [ERROR] Error during Reddit scraping: received 401 HTTP response
2025-05-15 17:35:08,667 [ERROR] Detailed error:
Traceback (most recent call last):
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\src\scheduler\jobs\reddit_scraper.py", line 97, in scrape_reddit
    for post in subreddit.hot(limit=post_limit):
                ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 66, in __next__
    self._next_batch()
    ~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 90, in _next_batch
    self._listing = self._reddit.get(self.url, params=self.params)
                    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 731, in get
    return self._objectify_request(method="GET", params=params, path=path)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 514, in _objectify_request
    self.request(
    ~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 963, in request
    return self._core.request(
           ~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 328, in request
    return self._request_with_retries(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<5 lines>...
        url=url,
        ^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 234, in _request_with_retries
    response, saved_exception = self._make_request(
                                ~~~~~~~~~~~~~~~~~~^
        data,
        ^^^^^
    ...<6 lines>...
        url,
        ^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 186, in _make_request
    response = self._rate_limiter.call(
        self._requestor.request,
    ...<8 lines>...
        timeout=timeout,
    )
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\rate_limit.py", line 46, in call
    kwargs["headers"] = set_header_callback()
                        ~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 282, in _set_header_callback
    self._authorizer.refresh()
    ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 378, in refresh
    self._request_token(grant_type="client_credentials", **additional_kwargs)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 155, in _request_token
    response = self._authenticator._post(url=url, **data)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 59, in _post
    raise ResponseException(response)
prawcore.exceptions.ResponseException: received 401 HTTP response
2025-05-15 17:37:15,549 [INFO] Starting Reddit scraping...
2025-05-15 17:37:15,558 [INFO] Successfully connected to Reddit API
2025-05-15 17:37:15,558 [INFO] Scraping subreddit: r/all
2025-05-15 17:37:15,863 [ERROR] Error during Reddit scraping: received 401 HTTP response
2025-05-15 17:37:15,863 [ERROR] Detailed error:
Traceback (most recent call last):
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\src\scheduler\jobs\reddit_scraper.py", line 97, in scrape_reddit
    for post in subreddit.hot(limit=post_limit):
                ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 66, in __next__
    self._next_batch()
    ~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 90, in _next_batch
    self._listing = self._reddit.get(self.url, params=self.params)
                    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 731, in get
    return self._objectify_request(method="GET", params=params, path=path)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 514, in _objectify_request
    self.request(
    ~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 963, in request
    return self._core.request(
           ~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 328, in request
    return self._request_with_retries(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<5 lines>...
        url=url,
        ^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 234, in _request_with_retries
    response, saved_exception = self._make_request(
                                ~~~~~~~~~~~~~~~~~~^
        data,
        ^^^^^
    ...<6 lines>...
        url,
        ^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 186, in _make_request
    response = self._rate_limiter.call(
        self._requestor.request,
    ...<8 lines>...
        timeout=timeout,
    )
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\rate_limit.py", line 46, in call
    kwargs["headers"] = set_header_callback()
                        ~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 282, in _set_header_callback
    self._authorizer.refresh()
    ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 378, in refresh
    self._request_token(grant_type="client_credentials", **additional_kwargs)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 155, in _request_token
    response = self._authenticator._post(url=url, **data)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 59, in _post
    raise ResponseException(response)
prawcore.exceptions.ResponseException: received 401 HTTP response
2025-05-15 17:38:53,728 [INFO] Starting Reddit scraping...
2025-05-15 17:38:53,729 [INFO] Successfully connected to Reddit API
2025-05-15 17:38:53,729 [INFO] Scraping subreddit: r/all
2025-05-15 17:38:54,103 [ERROR] Error during Reddit scraping: received 401 HTTP response
2025-05-15 17:38:54,103 [ERROR] Detailed error:
Traceback (most recent call last):
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\src\scheduler\jobs\reddit_scraper.py", line 97, in scrape_reddit
    for post in subreddit.hot(limit=post_limit):
                ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 66, in __next__
    self._next_batch()
    ~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 90, in _next_batch
    self._listing = self._reddit.get(self.url, params=self.params)
                    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 731, in get
    return self._objectify_request(method="GET", params=params, path=path)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 514, in _objectify_request
    self.request(
    ~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 963, in request
    return self._core.request(
           ~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 328, in request
    return self._request_with_retries(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<5 lines>...
        url=url,
        ^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 234, in _request_with_retries
    response, saved_exception = self._make_request(
                                ~~~~~~~~~~~~~~~~~~^
        data,
        ^^^^^
    ...<6 lines>...
        url,
        ^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 186, in _make_request
    response = self._rate_limiter.call(
        self._requestor.request,
    ...<8 lines>...
        timeout=timeout,
    )
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\rate_limit.py", line 46, in call
    kwargs["headers"] = set_header_callback()
                        ~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 282, in _set_header_callback
    self._authorizer.refresh()
    ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 378, in refresh
    self._request_token(grant_type="client_credentials", **additional_kwargs)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 155, in _request_token
    response = self._authenticator._post(url=url, **data)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 59, in _post
    raise ResponseException(response)
prawcore.exceptions.ResponseException: received 401 HTTP response
2025-05-15 18:32:32,750 [INFO] Starting Reddit scraping...
2025-05-15 18:32:32,817 [INFO] Successfully connected to Reddit API
2025-05-15 18:32:32,818 [INFO] Scraping subreddit: r/all
2025-05-15 18:32:33,077 [ERROR] Error during Reddit scraping: received 401 HTTP response
2025-05-15 18:32:33,078 [ERROR] Detailed error:
Traceback (most recent call last):
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\src\scheduler\jobs\reddit_scraper.py", line 97, in scrape_reddit
    for post in subreddit.hot(limit=post_limit):
                ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 66, in __next__
    self._next_batch()
    ~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 90, in _next_batch
    self._listing = self._reddit.get(self.url, params=self.params)
                    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 731, in get
    return self._objectify_request(method="GET", params=params, path=path)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 514, in _objectify_request
    self.request(
    ~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 963, in request
    return self._core.request(
           ~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 328, in request
    return self._request_with_retries(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<5 lines>...
        url=url,
        ^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 234, in _request_with_retries
    response, saved_exception = self._make_request(
                                ~~~~~~~~~~~~~~~~~~^
        data,
        ^^^^^
    ...<6 lines>...
        url,
        ^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 186, in _make_request
    response = self._rate_limiter.call(
        self._requestor.request,
    ...<8 lines>...
        timeout=timeout,
    )
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\rate_limit.py", line 46, in call
    kwargs["headers"] = set_header_callback()
                        ~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 282, in _set_header_callback
    self._authorizer.refresh()
    ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 378, in refresh
    self._request_token(grant_type="client_credentials", **additional_kwargs)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 155, in _request_token
    response = self._authenticator._post(url=url, **data)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 59, in _post
    raise ResponseException(response)
prawcore.exceptions.ResponseException: received 401 HTTP response
2025-05-15 18:39:11,421 [INFO] Starting Reddit scraping...
2025-05-15 18:39:11,433 [INFO] Successfully connected to Reddit API
2025-05-15 18:39:11,433 [INFO] Scraping subreddit: r/all
2025-05-15 18:39:11,617 [ERROR] Error during Reddit scraping: received 401 HTTP response
2025-05-15 18:39:11,617 [ERROR] Detailed error:
Traceback (most recent call last):
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\src\scheduler\jobs\reddit_scraper.py", line 90, in scrape_reddit
    for post in subreddit.hot(limit=post_limit):
                ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 66, in __next__
    self._next_batch()
    ~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 90, in _next_batch
    self._listing = self._reddit.get(self.url, params=self.params)
                    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 731, in get
    return self._objectify_request(method="GET", params=params, path=path)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 514, in _objectify_request
    self.request(
    ~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 963, in request
    return self._core.request(
           ~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 328, in request
    return self._request_with_retries(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<5 lines>...
        url=url,
        ^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 234, in _request_with_retries
    response, saved_exception = self._make_request(
                                ~~~~~~~~~~~~~~~~~~^
        data,
        ^^^^^
    ...<6 lines>...
        url,
        ^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 186, in _make_request
    response = self._rate_limiter.call(
        self._requestor.request,
    ...<8 lines>...
        timeout=timeout,
    )
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\rate_limit.py", line 46, in call
    kwargs["headers"] = set_header_callback()
                        ~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 282, in _set_header_callback
    self._authorizer.refresh()
    ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 378, in refresh
    self._request_token(grant_type="client_credentials", **additional_kwargs)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 155, in _request_token
    response = self._authenticator._post(url=url, **data)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 59, in _post
    raise ResponseException(response)
prawcore.exceptions.ResponseException: received 401 HTTP response
2025-05-15 18:42:38,668 [INFO] Starting Reddit scraping...
2025-05-15 18:42:38,669 [INFO] Successfully connected to Reddit API
2025-05-15 18:42:38,669 [INFO] Scraping subreddit: r/all
2025-05-15 18:42:38,863 [ERROR] Error during Reddit scraping: received 401 HTTP response
2025-05-15 18:42:38,863 [ERROR] Detailed error:
Traceback (most recent call last):
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\src\scheduler\jobs\reddit_scraper.py", line 97, in scrape_reddit
    "author": str(post.author) if post.author else None,
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 66, in __next__
    self._next_batch()
    ~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 90, in _next_batch
    self._listing = self._reddit.get(self.url, params=self.params)
                    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 731, in get
    return self._objectify_request(method="GET", params=params, path=path)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 514, in _objectify_request
    self.request(
    ~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 963, in request
    return self._core.request(
           ~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 328, in request
    return self._request_with_retries(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<5 lines>...
        url=url,
        ^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 234, in _request_with_retries
    response, saved_exception = self._make_request(
                                ~~~~~~~~~~~~~~~~~~^
        data,
        ^^^^^
    ...<6 lines>...
        url,
        ^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 186, in _make_request
    response = self._rate_limiter.call(
        self._requestor.request,
    ...<8 lines>...
        timeout=timeout,
    )
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\rate_limit.py", line 46, in call
    kwargs["headers"] = set_header_callback()
                        ~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 282, in _set_header_callback
    self._authorizer.refresh()
    ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 378, in refresh
    self._request_token(grant_type="client_credentials", **additional_kwargs)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 155, in _request_token
    response = self._authenticator._post(url=url, **data)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 59, in _post
    raise ResponseException(response)
prawcore.exceptions.ResponseException: received 401 HTTP response
2025-05-15 18:42:41,961 [INFO] Starting Reddit scraping...
2025-05-15 18:42:41,962 [INFO] Successfully connected to Reddit API
2025-05-15 18:42:41,963 [INFO] Scraping subreddit: r/all
2025-05-15 18:42:42,135 [ERROR] Error during Reddit scraping: received 401 HTTP response
2025-05-15 18:42:42,136 [ERROR] Detailed error:
Traceback (most recent call last):
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\src\scheduler\jobs\reddit_scraper.py", line 90, in scrape_reddit
    for post in subreddit.hot(limit=post_limit):
                ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 66, in __next__
    self._next_batch()
    ~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 90, in _next_batch
    self._listing = self._reddit.get(self.url, params=self.params)
                    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 731, in get
    return self._objectify_request(method="GET", params=params, path=path)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 514, in _objectify_request
    self.request(
    ~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 963, in request
    return self._core.request(
           ~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 328, in request
    return self._request_with_retries(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<5 lines>...
        url=url,
        ^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 234, in _request_with_retries
    response, saved_exception = self._make_request(
                                ~~~~~~~~~~~~~~~~~~^
        data,
        ^^^^^
    ...<6 lines>...
        url,
        ^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 186, in _make_request
    response = self._rate_limiter.call(
        self._requestor.request,
    ...<8 lines>...
        timeout=timeout,
    )
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\rate_limit.py", line 46, in call
    kwargs["headers"] = set_header_callback()
                        ~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 282, in _set_header_callback
    self._authorizer.refresh()
    ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 378, in refresh
    self._request_token(grant_type="client_credentials", **additional_kwargs)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 155, in _request_token
    response = self._authenticator._post(url=url, **data)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 59, in _post
    raise ResponseException(response)
prawcore.exceptions.ResponseException: received 401 HTTP response
2025-05-15 18:44:57,127 [INFO] Starting Reddit scraping...
2025-05-15 18:44:57,129 [INFO] Successfully connected to Reddit API
2025-05-15 18:44:57,129 [INFO] Scraping subreddit: r/all
2025-05-15 18:44:57,331 [ERROR] Error during Reddit scraping: received 401 HTTP response
2025-05-15 18:44:57,331 [ERROR] Detailed error:
Traceback (most recent call last):
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\src\scheduler\jobs\reddit_scraper.py", line 90, in scrape_reddit
    for post in subreddit.hot(limit=post_limit):
                ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 66, in __next__
    self._next_batch()
    ~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 90, in _next_batch
    self._listing = self._reddit.get(self.url, params=self.params)
                    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 731, in get
    return self._objectify_request(method="GET", params=params, path=path)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 514, in _objectify_request
    self.request(
    ~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 963, in request
    return self._core.request(
           ~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 328, in request
    return self._request_with_retries(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<5 lines>...
        url=url,
        ^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 234, in _request_with_retries
    response, saved_exception = self._make_request(
                                ~~~~~~~~~~~~~~~~~~^
        data,
        ^^^^^
    ...<6 lines>...
        url,
        ^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 186, in _make_request
    response = self._rate_limiter.call(
        self._requestor.request,
    ...<8 lines>...
        timeout=timeout,
    )
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\rate_limit.py", line 46, in call
    kwargs["headers"] = set_header_callback()
                        ~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 282, in _set_header_callback
    self._authorizer.refresh()
    ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 378, in refresh
    self._request_token(grant_type="client_credentials", **additional_kwargs)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 155, in _request_token
    response = self._authenticator._post(url=url, **data)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 59, in _post
    raise ResponseException(response)
prawcore.exceptions.ResponseException: received 401 HTTP response
2025-05-15 18:56:04,286 [INFO] Starting Reddit scraping...
2025-05-15 18:56:04,286 [INFO] Connecting to Reddit API with ID: "jl1T...
2025-05-15 18:56:04,296 [INFO] Successfully connected to Reddit API
2025-05-15 18:56:04,296 [INFO] Scraping subreddit: r/all
2025-05-15 18:56:04,488 [ERROR] Error during Reddit scraping: received 401 HTTP response
2025-05-15 18:56:04,489 [ERROR] Detailed error:
Traceback (most recent call last):
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\src\scheduler\jobs\reddit_scraper.py", line 103, in scrape_reddit
    for post in subreddit.hot(limit=post_limit):
                ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 66, in __next__
    self._next_batch()
    ~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 90, in _next_batch
    self._listing = self._reddit.get(self.url, params=self.params)
                    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 731, in get
    return self._objectify_request(method="GET", params=params, path=path)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 514, in _objectify_request
    self.request(
    ~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 963, in request
    return self._core.request(
           ~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 328, in request
    return self._request_with_retries(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<5 lines>...
        url=url,
        ^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 234, in _request_with_retries
    response, saved_exception = self._make_request(
                                ~~~~~~~~~~~~~~~~~~^
        data,
        ^^^^^
    ...<6 lines>...
        url,
        ^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 186, in _make_request
    response = self._rate_limiter.call(
        self._requestor.request,
    ...<8 lines>...
        timeout=timeout,
    )
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\rate_limit.py", line 46, in call
    kwargs["headers"] = set_header_callback()
                        ~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 282, in _set_header_callback
    self._authorizer.refresh()
    ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 378, in refresh
    self._request_token(grant_type="client_credentials", **additional_kwargs)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 155, in _request_token
    response = self._authenticator._post(url=url, **data)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 59, in _post
    raise ResponseException(response)
prawcore.exceptions.ResponseException: received 401 HTTP response
2025-05-15 19:00:11,211 [INFO] Starting Reddit scraping...
2025-05-15 19:00:11,211 [INFO] Successfully connected to Reddit API
2025-05-15 19:00:11,211 [INFO] Scraping subreddit: r/all
2025-05-15 19:00:11,596 [ERROR] Error during Reddit scraping: received 401 HTTP response
2025-05-15 19:00:11,596 [ERROR] Detailed error:
Traceback (most recent call last):
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\src\scheduler\jobs\reddit_scraper.py", line 90, in scrape_reddit
    user_agent=user_agent
                ^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 66, in __next__
    self._next_batch()
    ~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 90, in _next_batch
    self._listing = self._reddit.get(self.url, params=self.params)
                    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 731, in get
    return self._objectify_request(method="GET", params=params, path=path)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 514, in _objectify_request
    self.request(
    ~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 963, in request
    return self._core.request(
           ~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 328, in request
    return self._request_with_retries(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<5 lines>...
        url=url,
        ^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 234, in _request_with_retries
    response, saved_exception = self._make_request(
                                ~~~~~~~~~~~~~~~~~~^
        data,
        ^^^^^
    ...<6 lines>...
        url,
        ^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 186, in _make_request
    response = self._rate_limiter.call(
        self._requestor.request,
    ...<8 lines>...
        timeout=timeout,
    )
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\rate_limit.py", line 46, in call
    kwargs["headers"] = set_header_callback()
                        ~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 282, in _set_header_callback
    self._authorizer.refresh()
    ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 378, in refresh
    self._request_token(grant_type="client_credentials", **additional_kwargs)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 155, in _request_token
    response = self._authenticator._post(url=url, **data)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 59, in _post
    raise ResponseException(response)
prawcore.exceptions.ResponseException: received 401 HTTP response
2025-05-15 19:01:54,538 [INFO] Starting Reddit scraping...
2025-05-15 19:01:54,538 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 19:01:54,539 [INFO] Successfully connected to Reddit API
2025-05-15 19:01:54,539 [INFO] Scraping subreddit: r/all
2025-05-15 19:01:56,827 [INFO] Found 6 posts in r/all
2025-05-15 19:01:56,827 [INFO] Scraping subreddit: r/popular
2025-05-15 19:01:58,459 [INFO] Found 11 posts in r/popular
2025-05-15 19:01:58,459 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 19:01:59,421 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 19:01:59,422 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 19:02:01,852 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 19:02:01,852 [INFO] Found 135 unique posts out of 138 total posts
2025-05-15 19:03:20,656 [INFO] Successfully processed 135 Reddit posts (118 inserted, 17 updated)
2025-05-15 19:05:19,058 [INFO] Starting Reddit scraping...
2025-05-15 19:05:19,059 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 19:05:19,060 [INFO] Successfully connected to Reddit API
2025-05-15 19:05:19,060 [INFO] Scraping subreddit: r/all
2025-05-15 19:05:20,785 [INFO] Found 6 posts in r/all
2025-05-15 19:05:20,786 [INFO] Scraping subreddit: r/popular
2025-05-15 19:05:22,198 [INFO] Found 11 posts in r/popular
2025-05-15 19:05:22,198 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 19:05:23,125 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 19:05:23,125 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 19:05:25,450 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 19:05:25,450 [INFO] Found 135 unique posts out of 138 total posts
2025-05-15 19:06:43,330 [INFO] Successfully processed 135 Reddit posts (1 inserted, 134 updated)
2025-05-15 19:09:58,664 [INFO] Starting Reddit scraping...
2025-05-15 19:09:58,664 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 19:09:58,666 [INFO] Successfully connected to Reddit API
2025-05-15 19:09:58,666 [INFO] Scraping subreddit: r/all
2025-05-15 19:10:00,414 [INFO] Found 6 posts in r/all
2025-05-15 19:10:00,415 [INFO] Scraping subreddit: r/popular
2025-05-15 19:10:01,822 [INFO] Found 9 posts in r/popular
2025-05-15 19:10:01,822 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 19:10:02,716 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 19:10:02,717 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 19:10:05,531 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 19:10:05,531 [INFO] Found 133 unique posts out of 136 total posts
2025-05-15 19:11:26,397 [INFO] Successfully processed 133 Reddit posts (0 inserted, 133 updated)
2025-05-15 19:11:27,265 [INFO] Starting Reddit scraping...
2025-05-15 19:11:27,265 [INFO] Connecting to Reddit API with ID: "jl1T...
2025-05-15 19:11:27,266 [INFO] Successfully connected to Reddit API
2025-05-15 19:11:27,266 [INFO] Scraping subreddit: r/all
2025-05-15 19:11:27,465 [ERROR] Error during Reddit scraping: received 401 HTTP response
2025-05-15 19:11:27,466 [ERROR] Detailed error:
Traceback (most recent call last):
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\src\scheduler\jobs\reddit_scraper.py", line 103, in scrape_reddit
    cur.execute("""
        ^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 66, in __next__
    self._next_batch()
    ~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 90, in _next_batch
    self._listing = self._reddit.get(self.url, params=self.params)
                    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 731, in get
    return self._objectify_request(method="GET", params=params, path=path)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 514, in _objectify_request
    self.request(
    ~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 963, in request
    return self._core.request(
           ~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 328, in request
    return self._request_with_retries(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<5 lines>...
        url=url,
        ^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 234, in _request_with_retries
    response, saved_exception = self._make_request(
                                ~~~~~~~~~~~~~~~~~~^
        data,
        ^^^^^
    ...<6 lines>...
        url,
        ^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 186, in _make_request
    response = self._rate_limiter.call(
        self._requestor.request,
    ...<8 lines>...
        timeout=timeout,
    )
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\rate_limit.py", line 46, in call
    kwargs["headers"] = set_header_callback()
                        ~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 282, in _set_header_callback
    self._authorizer.refresh()
    ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 378, in refresh
    self._request_token(grant_type="client_credentials", **additional_kwargs)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 155, in _request_token
    response = self._authenticator._post(url=url, **data)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 59, in _post
    raise ResponseException(response)
prawcore.exceptions.ResponseException: received 401 HTTP response
2025-05-15 19:15:28,234 [INFO] Starting Reddit scraping...
2025-05-15 19:15:28,234 [INFO] Successfully connected to Reddit API
2025-05-15 19:15:28,234 [INFO] Scraping subreddit: r/all
2025-05-15 19:15:28,737 [ERROR] Error during Reddit scraping: received 401 HTTP response
2025-05-15 19:15:28,738 [ERROR] Detailed error:
Traceback (most recent call last):
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\src\scheduler\jobs\reddit_scraper.py", line 90, in scrape_reddit
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 66, in __next__
    self._next_batch()
    ~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 90, in _next_batch
    self._listing = self._reddit.get(self.url, params=self.params)
                    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 731, in get
    return self._objectify_request(method="GET", params=params, path=path)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 514, in _objectify_request
    self.request(
    ~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 963, in request
    return self._core.request(
           ~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 328, in request
    return self._request_with_retries(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<5 lines>...
        url=url,
        ^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 234, in _request_with_retries
    response, saved_exception = self._make_request(
                                ~~~~~~~~~~~~~~~~~~^
        data,
        ^^^^^
    ...<6 lines>...
        url,
        ^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 186, in _make_request
    response = self._rate_limiter.call(
        self._requestor.request,
    ...<8 lines>...
        timeout=timeout,
    )
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\rate_limit.py", line 46, in call
    kwargs["headers"] = set_header_callback()
                        ~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 282, in _set_header_callback
    self._authorizer.refresh()
    ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 378, in refresh
    self._request_token(grant_type="client_credentials", **additional_kwargs)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 155, in _request_token
    response = self._authenticator._post(url=url, **data)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 59, in _post
    raise ResponseException(response)
prawcore.exceptions.ResponseException: received 401 HTTP response
2025-05-15 19:18:40,068 [INFO] Starting Reddit scraping...
2025-05-15 19:18:40,068 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 19:18:40,069 [INFO] Successfully connected to Reddit API
2025-05-15 19:18:40,069 [INFO] Scraping subreddit: r/all
2025-05-15 19:18:41,849 [INFO] Found 5 posts in r/all
2025-05-15 19:18:41,850 [INFO] Scraping subreddit: r/popular
2025-05-15 19:18:43,267 [INFO] Found 9 posts in r/popular
2025-05-15 19:18:43,267 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 19:18:44,229 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 19:18:44,230 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 19:18:46,776 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 19:18:46,777 [INFO] Found 132 unique posts out of 135 total posts
2025-05-15 19:20:04,221 [INFO] Successfully processed 132 Reddit posts (0 inserted, 132 updated)
2025-05-15 19:22:04,320 [INFO] Starting Reddit scraping...
2025-05-15 19:22:04,321 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 19:22:04,321 [INFO] Successfully connected to Reddit API
2025-05-15 19:22:04,321 [INFO] Scraping subreddit: r/all
2025-05-15 19:22:06,553 [INFO] Found 5 posts in r/all
2025-05-15 19:22:06,553 [INFO] Scraping subreddit: r/popular
2025-05-15 19:22:07,905 [INFO] Found 9 posts in r/popular
2025-05-15 19:22:07,906 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 19:22:09,198 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 19:22:09,198 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 19:22:11,874 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 19:22:11,875 [INFO] Found 132 unique posts out of 135 total posts
2025-05-15 19:23:29,181 [INFO] Successfully processed 132 Reddit posts (0 inserted, 132 updated)
2025-05-15 19:26:48,069 [INFO] Starting Reddit scraping...
2025-05-15 19:26:48,070 [INFO] Connecting to Reddit API with ID: "jl1T...
2025-05-15 19:26:48,070 [INFO] Successfully connected to Reddit API
2025-05-15 19:26:48,070 [INFO] Scraping subreddit: r/all
2025-05-15 19:26:48,278 [ERROR] Error during Reddit scraping: received 401 HTTP response
2025-05-15 19:26:48,278 [ERROR] Detailed error:
Traceback (most recent call last):
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\src\scheduler\jobs\reddit_scraper.py", line 103, in scrape_reddit
    cur.execute("""
        ^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 66, in __next__
    self._next_batch()
    ~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 90, in _next_batch
    self._listing = self._reddit.get(self.url, params=self.params)
                    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 731, in get
    return self._objectify_request(method="GET", params=params, path=path)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 514, in _objectify_request
    self.request(
    ~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 963, in request
    return self._core.request(
           ~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 328, in request
    return self._request_with_retries(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<5 lines>...
        url=url,
        ^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 234, in _request_with_retries
    response, saved_exception = self._make_request(
                                ~~~~~~~~~~~~~~~~~~^
        data,
        ^^^^^
    ...<6 lines>...
        url,
        ^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 186, in _make_request
    response = self._rate_limiter.call(
        self._requestor.request,
    ...<8 lines>...
        timeout=timeout,
    )
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\rate_limit.py", line 46, in call
    kwargs["headers"] = set_header_callback()
                        ~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 282, in _set_header_callback
    self._authorizer.refresh()
    ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 378, in refresh
    self._request_token(grant_type="client_credentials", **additional_kwargs)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 155, in _request_token
    response = self._authenticator._post(url=url, **data)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 59, in _post
    raise ResponseException(response)
prawcore.exceptions.ResponseException: received 401 HTTP response
2025-05-15 19:26:51,266 [INFO] Starting Reddit scraping...
2025-05-15 19:26:51,266 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 19:26:51,267 [INFO] Successfully connected to Reddit API
2025-05-15 19:26:51,267 [INFO] Scraping subreddit: r/all
2025-05-15 19:26:52,862 [INFO] Found 6 posts in r/all
2025-05-15 19:26:52,862 [INFO] Scraping subreddit: r/popular
2025-05-15 19:26:54,151 [INFO] Found 9 posts in r/popular
2025-05-15 19:26:54,151 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 19:26:55,078 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 19:26:55,079 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 19:26:57,374 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 19:26:57,375 [INFO] Found 133 unique posts out of 136 total posts
2025-05-15 19:28:17,996 [INFO] Successfully processed 133 Reddit posts (1 inserted, 132 updated)
2025-05-15 19:30:45,283 [INFO] Starting Reddit scraping...
2025-05-15 19:30:45,284 [INFO] Successfully connected to Reddit API
2025-05-15 19:30:45,284 [INFO] Scraping subreddit: r/all
2025-05-15 19:30:45,486 [ERROR] Error during Reddit scraping: received 401 HTTP response
2025-05-15 19:30:45,487 [ERROR] Detailed error:
Traceback (most recent call last):
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\src\scheduler\jobs\reddit_scraper.py", line 90, in scrape_reddit
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 66, in __next__
    self._next_batch()
    ~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 90, in _next_batch
    self._listing = self._reddit.get(self.url, params=self.params)
                    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 731, in get
    return self._objectify_request(method="GET", params=params, path=path)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 514, in _objectify_request
    self.request(
    ~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 963, in request
    return self._core.request(
           ~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 328, in request
    return self._request_with_retries(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<5 lines>...
        url=url,
        ^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 234, in _request_with_retries
    response, saved_exception = self._make_request(
                                ~~~~~~~~~~~~~~~~~~^
        data,
        ^^^^^
    ...<6 lines>...
        url,
        ^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 186, in _make_request
    response = self._rate_limiter.call(
        self._requestor.request,
    ...<8 lines>...
        timeout=timeout,
    )
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\rate_limit.py", line 46, in call
    kwargs["headers"] = set_header_callback()
                        ~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 282, in _set_header_callback
    self._authorizer.refresh()
    ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 378, in refresh
    self._request_token(grant_type="client_credentials", **additional_kwargs)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 155, in _request_token
    response = self._authenticator._post(url=url, **data)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 59, in _post
    raise ResponseException(response)
prawcore.exceptions.ResponseException: received 401 HTTP response
2025-05-15 19:35:20,620 [INFO] Starting Reddit scraping...
2025-05-15 19:35:20,620 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 19:35:20,621 [INFO] Successfully connected to Reddit API
2025-05-15 19:35:20,621 [INFO] Scraping subreddit: r/all
2025-05-15 19:35:22,258 [INFO] Found 6 posts in r/all
2025-05-15 19:35:22,259 [INFO] Scraping subreddit: r/popular
2025-05-15 19:35:23,619 [INFO] Found 9 posts in r/popular
2025-05-15 19:35:23,619 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 19:35:25,091 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 19:35:25,091 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 19:35:27,165 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 19:35:27,165 [INFO] Found 133 unique posts out of 136 total posts
2025-05-15 19:36:45,552 [INFO] Successfully processed 133 Reddit posts (1 inserted, 132 updated)
2025-05-15 19:38:50,839 [INFO] Starting Reddit scraping...
2025-05-15 19:38:50,840 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 19:38:50,840 [INFO] Successfully connected to Reddit API
2025-05-15 19:38:50,840 [INFO] Scraping subreddit: r/all
2025-05-15 19:38:52,430 [INFO] Found 5 posts in r/all
2025-05-15 19:38:52,431 [INFO] Scraping subreddit: r/popular
2025-05-15 19:38:53,671 [INFO] Found 10 posts in r/popular
2025-05-15 19:38:53,671 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 19:38:54,699 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 19:38:54,700 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 19:38:57,456 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 19:38:57,457 [INFO] Found 133 unique posts out of 136 total posts
2025-05-15 19:40:17,057 [INFO] Successfully processed 133 Reddit posts (1 inserted, 132 updated)
2025-05-15 19:42:10,276 [INFO] Starting Reddit scraping...
2025-05-15 19:42:10,276 [INFO] Connecting to Reddit API with ID: "jl1T...
2025-05-15 19:42:10,276 [INFO] Successfully connected to Reddit API
2025-05-15 19:42:10,276 [INFO] Scraping subreddit: r/all
2025-05-15 19:42:10,574 [ERROR] Error during Reddit scraping: received 401 HTTP response
2025-05-15 19:42:10,574 [ERROR] Detailed error:
Traceback (most recent call last):
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\src\scheduler\jobs\reddit_scraper.py", line 103, in scrape_reddit
    cur.execute("""
        ^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 66, in __next__
    self._next_batch()
    ~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 90, in _next_batch
    self._listing = self._reddit.get(self.url, params=self.params)
                    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 731, in get
    return self._objectify_request(method="GET", params=params, path=path)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 514, in _objectify_request
    self.request(
    ~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 963, in request
    return self._core.request(
           ~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 328, in request
    return self._request_with_retries(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<5 lines>...
        url=url,
        ^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 234, in _request_with_retries
    response, saved_exception = self._make_request(
                                ~~~~~~~~~~~~~~~~~~^
        data,
        ^^^^^
    ...<6 lines>...
        url,
        ^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 186, in _make_request
    response = self._rate_limiter.call(
        self._requestor.request,
    ...<8 lines>...
        timeout=timeout,
    )
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\rate_limit.py", line 46, in call
    kwargs["headers"] = set_header_callback()
                        ~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 282, in _set_header_callback
    self._authorizer.refresh()
    ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 378, in refresh
    self._request_token(grant_type="client_credentials", **additional_kwargs)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 155, in _request_token
    response = self._authenticator._post(url=url, **data)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 59, in _post
    raise ResponseException(response)
prawcore.exceptions.ResponseException: received 401 HTTP response
2025-05-15 19:43:42,678 [INFO] Starting Reddit scraping...
2025-05-15 19:43:42,679 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 19:43:42,679 [INFO] Successfully connected to Reddit API
2025-05-15 19:43:42,680 [INFO] Scraping subreddit: r/all
2025-05-15 19:43:45,054 [INFO] Found 5 posts in r/all
2025-05-15 19:43:45,054 [INFO] Scraping subreddit: r/popular
2025-05-15 19:43:46,416 [INFO] Found 11 posts in r/popular
2025-05-15 19:43:46,417 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 19:43:47,893 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 19:43:47,893 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 19:43:50,270 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 19:43:50,270 [INFO] Found 134 unique posts out of 137 total posts
2025-05-15 19:45:08,264 [INFO] Successfully processed 134 Reddit posts (1 inserted, 133 updated)
2025-05-15 19:46:02,478 [INFO] Starting Reddit scraping...
2025-05-15 19:46:02,479 [INFO] Successfully connected to Reddit API
2025-05-15 19:46:02,479 [INFO] Scraping subreddit: r/all
2025-05-15 19:46:02,692 [ERROR] Error during Reddit scraping: received 401 HTTP response
2025-05-15 19:46:02,692 [ERROR] Detailed error:
Traceback (most recent call last):
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\src\scheduler\jobs\reddit_scraper.py", line 90, in scrape_reddit
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 66, in __next__
    self._next_batch()
    ~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 90, in _next_batch
    self._listing = self._reddit.get(self.url, params=self.params)
                    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 731, in get
    return self._objectify_request(method="GET", params=params, path=path)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 514, in _objectify_request
    self.request(
    ~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 963, in request
    return self._core.request(
           ~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 328, in request
    return self._request_with_retries(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<5 lines>...
        url=url,
        ^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 234, in _request_with_retries
    response, saved_exception = self._make_request(
                                ~~~~~~~~~~~~~~~~~~^
        data,
        ^^^^^
    ...<6 lines>...
        url,
        ^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 186, in _make_request
    response = self._rate_limiter.call(
        self._requestor.request,
    ...<8 lines>...
        timeout=timeout,
    )
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\rate_limit.py", line 46, in call
    kwargs["headers"] = set_header_callback()
                        ~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 282, in _set_header_callback
    self._authorizer.refresh()
    ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 378, in refresh
    self._request_token(grant_type="client_credentials", **additional_kwargs)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 155, in _request_token
    response = self._authenticator._post(url=url, **data)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 59, in _post
    raise ResponseException(response)
prawcore.exceptions.ResponseException: received 401 HTTP response
2025-05-15 19:52:05,065 [INFO] Starting Reddit scraping...
2025-05-15 19:52:05,066 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 19:52:05,066 [INFO] Successfully connected to Reddit API
2025-05-15 19:52:05,066 [INFO] Scraping subreddit: r/all
2025-05-15 19:52:06,712 [INFO] Found 5 posts in r/all
2025-05-15 19:52:06,712 [INFO] Scraping subreddit: r/popular
2025-05-15 19:52:08,019 [INFO] Found 8 posts in r/popular
2025-05-15 19:52:08,020 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 19:52:09,021 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 19:52:09,021 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 19:52:11,775 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 19:52:11,775 [INFO] Found 131 unique posts out of 134 total posts
2025-05-15 19:53:29,519 [INFO] Successfully processed 131 Reddit posts (0 inserted, 131 updated)
2025-05-15 19:55:36,612 [INFO] Starting Reddit scraping...
2025-05-15 19:55:36,612 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 19:55:36,771 [INFO] Successfully connected to Reddit API
2025-05-15 19:55:36,771 [INFO] Scraping subreddit: r/all
2025-05-15 19:55:38,258 [INFO] Starting Reddit scraping...
2025-05-15 19:55:38,258 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 19:55:38,259 [INFO] Successfully connected to Reddit API
2025-05-15 19:55:38,259 [INFO] Scraping subreddit: r/all
2025-05-15 19:55:38,421 [INFO] Found 6 posts in r/all
2025-05-15 19:55:38,421 [INFO] Scraping subreddit: r/popular
2025-05-15 19:55:39,947 [INFO] Found 9 posts in r/popular
2025-05-15 19:55:39,947 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 19:55:39,971 [INFO] Found 6 posts in r/all
2025-05-15 19:55:39,971 [INFO] Scraping subreddit: r/popular
2025-05-15 19:55:40,998 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 19:55:40,999 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 19:55:41,276 [INFO] Found 9 posts in r/popular
2025-05-15 19:55:41,276 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 19:55:42,256 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 19:55:42,257 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 19:55:43,183 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 19:55:43,184 [INFO] Found 133 unique posts out of 136 total posts
2025-05-15 19:55:44,318 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 19:55:44,318 [INFO] Found 133 unique posts out of 136 total posts
2025-05-15 19:57:02,379 [INFO] Successfully processed 133 Reddit posts (1 inserted, 132 updated)
2025-05-15 19:57:05,037 [INFO] Successfully processed 133 Reddit posts (0 inserted, 133 updated)
2025-05-15 19:57:33,517 [INFO] Starting Reddit scraping...
2025-05-15 19:57:33,517 [INFO] Connecting to Reddit API with ID: "jl1T...
2025-05-15 19:57:33,518 [INFO] Successfully connected to Reddit API
2025-05-15 19:57:33,518 [INFO] Scraping subreddit: r/all
2025-05-15 19:57:33,817 [ERROR] Error during Reddit scraping: received 401 HTTP response
2025-05-15 19:57:33,817 [ERROR] Detailed error:
Traceback (most recent call last):
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\src\scheduler\jobs\reddit_scraper.py", line 103, in scrape_reddit
    cur.execute("""
        ^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 66, in __next__
    self._next_batch()
    ~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 90, in _next_batch
    self._listing = self._reddit.get(self.url, params=self.params)
                    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 731, in get
    return self._objectify_request(method="GET", params=params, path=path)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 514, in _objectify_request
    self.request(
    ~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 963, in request
    return self._core.request(
           ~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 328, in request
    return self._request_with_retries(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<5 lines>...
        url=url,
        ^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 234, in _request_with_retries
    response, saved_exception = self._make_request(
                                ~~~~~~~~~~~~~~~~~~^
        data,
        ^^^^^
    ...<6 lines>...
        url,
        ^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 186, in _make_request
    response = self._rate_limiter.call(
        self._requestor.request,
    ...<8 lines>...
        timeout=timeout,
    )
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\rate_limit.py", line 46, in call
    kwargs["headers"] = set_header_callback()
                        ~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 282, in _set_header_callback
    self._authorizer.refresh()
    ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 378, in refresh
    self._request_token(grant_type="client_credentials", **additional_kwargs)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 155, in _request_token
    response = self._authenticator._post(url=url, **data)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 59, in _post
    raise ResponseException(response)
prawcore.exceptions.ResponseException: received 401 HTTP response
2025-05-15 20:00:32,960 [INFO] Starting Reddit scraping...
2025-05-15 20:00:32,960 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 20:00:32,960 [INFO] Successfully connected to Reddit API
2025-05-15 20:00:32,961 [INFO] Scraping subreddit: r/all
2025-05-15 20:00:35,825 [INFO] Found 6 posts in r/all
2025-05-15 20:00:35,825 [INFO] Scraping subreddit: r/popular
2025-05-15 20:00:37,853 [INFO] Found 9 posts in r/popular
2025-05-15 20:00:37,853 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 20:00:39,547 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 20:00:39,548 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 20:00:44,203 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 20:00:44,204 [INFO] Found 133 unique posts out of 136 total posts
2025-05-15 20:01:19,105 [INFO] Starting Reddit scraping...
2025-05-15 20:01:19,106 [INFO] Successfully connected to Reddit API
2025-05-15 20:01:19,106 [INFO] Scraping subreddit: r/all
2025-05-15 20:01:19,339 [ERROR] Error during Reddit scraping: received 401 HTTP response
2025-05-15 20:01:19,340 [ERROR] Detailed error:
Traceback (most recent call last):
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\src\scheduler\jobs\reddit_scraper.py", line 90, in scrape_reddit
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 66, in __next__
    self._next_batch()
    ~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 90, in _next_batch
    self._listing = self._reddit.get(self.url, params=self.params)
                    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 731, in get
    return self._objectify_request(method="GET", params=params, path=path)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 514, in _objectify_request
    self.request(
    ~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 963, in request
    return self._core.request(
           ~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 328, in request
    return self._request_with_retries(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<5 lines>...
        url=url,
        ^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 234, in _request_with_retries
    response, saved_exception = self._make_request(
                                ~~~~~~~~~~~~~~~~~~^
        data,
        ^^^^^
    ...<6 lines>...
        url,
        ^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 186, in _make_request
    response = self._rate_limiter.call(
        self._requestor.request,
    ...<8 lines>...
        timeout=timeout,
    )
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\rate_limit.py", line 46, in call
    kwargs["headers"] = set_header_callback()
                        ~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 282, in _set_header_callback
    self._authorizer.refresh()
    ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 378, in refresh
    self._request_token(grant_type="client_credentials", **additional_kwargs)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 155, in _request_token
    response = self._authenticator._post(url=url, **data)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 59, in _post
    raise ResponseException(response)
prawcore.exceptions.ResponseException: received 401 HTTP response
2025-05-15 20:02:03,862 [INFO] Successfully processed 133 Reddit posts (0 inserted, 133 updated)
2025-05-15 20:08:45,676 [INFO] Starting Reddit scraping...
2025-05-15 20:08:45,677 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 20:08:45,677 [INFO] Successfully connected to Reddit API
2025-05-15 20:08:45,677 [INFO] Scraping subreddit: r/all
2025-05-15 20:08:47,459 [INFO] Found 6 posts in r/all
2025-05-15 20:08:47,460 [INFO] Scraping subreddit: r/popular
2025-05-15 20:08:48,880 [INFO] Found 10 posts in r/popular
2025-05-15 20:08:48,880 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 20:08:49,900 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 20:08:49,900 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 20:08:52,635 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 20:08:52,636 [INFO] Found 134 unique posts out of 137 total posts
2025-05-15 20:10:12,659 [INFO] Successfully processed 134 Reddit posts (1 inserted, 133 updated)
2025-05-15 20:12:23,893 [INFO] Starting Reddit scraping...
2025-05-15 20:12:23,893 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 20:12:23,893 [INFO] Successfully connected to Reddit API
2025-05-15 20:12:23,893 [INFO] Scraping subreddit: r/all
2025-05-15 20:12:26,049 [INFO] Found 6 posts in r/all
2025-05-15 20:12:26,049 [INFO] Scraping subreddit: r/popular
2025-05-15 20:12:27,373 [INFO] Found 10 posts in r/popular
2025-05-15 20:12:27,374 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 20:12:28,467 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 20:12:28,467 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 20:12:31,179 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 20:12:31,180 [INFO] Found 134 unique posts out of 137 total posts
2025-05-15 20:12:53,726 [INFO] Starting Reddit scraping...
2025-05-15 20:12:53,727 [INFO] Connecting to Reddit API with ID: "jl1T...
2025-05-15 20:12:53,727 [INFO] Successfully connected to Reddit API
2025-05-15 20:12:53,727 [INFO] Scraping subreddit: r/all
2025-05-15 20:12:53,993 [ERROR] Error during Reddit scraping: received 401 HTTP response
2025-05-15 20:12:53,994 [ERROR] Detailed error:
Traceback (most recent call last):
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\src\scheduler\jobs\reddit_scraper.py", line 103, in scrape_reddit
    cur.execute("""
        ^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 66, in __next__
    self._next_batch()
    ~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 90, in _next_batch
    self._listing = self._reddit.get(self.url, params=self.params)
                    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 731, in get
    return self._objectify_request(method="GET", params=params, path=path)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 514, in _objectify_request
    self.request(
    ~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 963, in request
    return self._core.request(
           ~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 328, in request
    return self._request_with_retries(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<5 lines>...
        url=url,
        ^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 234, in _request_with_retries
    response, saved_exception = self._make_request(
                                ~~~~~~~~~~~~~~~~~~^
        data,
        ^^^^^
    ...<6 lines>...
        url,
        ^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 186, in _make_request
    response = self._rate_limiter.call(
        self._requestor.request,
    ...<8 lines>...
        timeout=timeout,
    )
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\rate_limit.py", line 46, in call
    kwargs["headers"] = set_header_callback()
                        ~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 282, in _set_header_callback
    self._authorizer.refresh()
    ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 378, in refresh
    self._request_token(grant_type="client_credentials", **additional_kwargs)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 155, in _request_token
    response = self._authenticator._post(url=url, **data)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 59, in _post
    raise ResponseException(response)
prawcore.exceptions.ResponseException: received 401 HTTP response
2025-05-15 20:13:49,971 [INFO] Successfully processed 134 Reddit posts (0 inserted, 134 updated)
2025-05-15 20:16:36,510 [INFO] Starting Reddit scraping...
2025-05-15 20:16:36,510 [INFO] Successfully connected to Reddit API
2025-05-15 20:16:36,510 [INFO] Scraping subreddit: r/all
2025-05-15 20:16:36,702 [ERROR] Error during Reddit scraping: received 401 HTTP response
2025-05-15 20:16:36,702 [ERROR] Detailed error:
Traceback (most recent call last):
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\src\scheduler\jobs\reddit_scraper.py", line 90, in scrape_reddit
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 66, in __next__
    self._next_batch()
    ~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\models\listing\generator.py", line 90, in _next_batch
    self._listing = self._reddit.get(self.url, params=self.params)
                    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 731, in get
    return self._objectify_request(method="GET", params=params, path=path)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 514, in _objectify_request
    self.request(
    ~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\util\deprecate_args.py", line 46, in wrapped
    return func(**dict(zip(_old_args, args)), **kwargs)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\praw\reddit.py", line 963, in request
    return self._core.request(
           ~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<4 lines>...
        path=path,
        ^^^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 328, in request
    return self._request_with_retries(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^
        data=data,
        ^^^^^^^^^^
    ...<5 lines>...
        url=url,
        ^^^^^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 234, in _request_with_retries
    response, saved_exception = self._make_request(
                                ~~~~~~~~~~~~~~~~~~^
        data,
        ^^^^^
    ...<6 lines>...
        url,
        ^^^^
    )
    ^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 186, in _make_request
    response = self._rate_limiter.call(
        self._requestor.request,
    ...<8 lines>...
        timeout=timeout,
    )
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\rate_limit.py", line 46, in call
    kwargs["headers"] = set_header_callback()
                        ~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\sessions.py", line 282, in _set_header_callback
    self._authorizer.refresh()
    ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 378, in refresh
    self._request_token(grant_type="client_credentials", **additional_kwargs)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 155, in _request_token
    response = self._authenticator._post(url=url, **data)
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\venv\Lib\site-packages\prawcore\auth.py", line 59, in _post
    raise ResponseException(response)
prawcore.exceptions.ResponseException: received 401 HTTP response
2025-05-15 20:17:26,826 [INFO] Starting Reddit scraping...
2025-05-15 20:17:26,826 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 20:17:26,826 [INFO] Successfully connected to Reddit API
2025-05-15 20:17:26,826 [INFO] Scraping subreddit: r/all
2025-05-15 20:17:28,757 [INFO] Found 6 posts in r/all
2025-05-15 20:17:28,757 [INFO] Scraping subreddit: r/popular
2025-05-15 20:17:30,200 [INFO] Found 10 posts in r/popular
2025-05-15 20:17:30,200 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 20:17:31,169 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 20:17:31,170 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 20:17:33,819 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 20:17:33,819 [INFO] Found 134 unique posts out of 137 total posts
2025-05-15 20:18:52,920 [INFO] Successfully processed 134 Reddit posts (0 inserted, 134 updated)
2025-05-15 20:23:55,322 [INFO] Starting Reddit scraping...
2025-05-15 20:23:55,323 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 20:23:55,331 [INFO] Successfully connected to Reddit API
2025-05-15 20:23:55,331 [INFO] Scraping subreddit: r/all
2025-05-15 20:23:56,772 [INFO] Found 5 posts in r/all
2025-05-15 20:23:56,772 [INFO] Scraping subreddit: r/popular
2025-05-15 20:23:58,031 [INFO] Found 9 posts in r/popular
2025-05-15 20:23:58,032 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 20:23:59,309 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 20:23:59,310 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 20:24:02,227 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 20:24:02,227 [INFO] Found 132 unique posts out of 135 total posts
2025-05-15 20:25:19,504 [INFO] Successfully processed 132 Reddit posts (0 inserted, 132 updated)
2025-05-15 20:34:15,897 [INFO] Starting Reddit scraping...
2025-05-15 20:34:15,897 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 20:34:15,898 [INFO] Successfully connected to Reddit API
2025-05-15 20:34:15,899 [INFO] Scraping subreddit: r/all
2025-05-15 20:34:17,889 [INFO] Found 5 posts in r/all
2025-05-15 20:34:17,889 [INFO] Scraping subreddit: r/popular
2025-05-15 20:34:19,696 [INFO] Found 9 posts in r/popular
2025-05-15 20:34:19,697 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 20:34:21,102 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 20:34:21,103 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 20:34:23,891 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 20:34:23,891 [INFO] Found 132 unique posts out of 135 total posts
2025-05-15 20:35:41,471 [INFO] Successfully processed 132 Reddit posts (0 inserted, 132 updated)
2025-05-15 20:40:58,762 [INFO] Starting Reddit scraping...
2025-05-15 20:40:58,762 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 20:40:58,763 [INFO] Successfully connected to Reddit API
2025-05-15 20:40:58,763 [INFO] Scraping subreddit: r/all
2025-05-15 20:41:00,744 [INFO] Found 5 posts in r/all
2025-05-15 20:41:00,744 [INFO] Scraping subreddit: r/popular
2025-05-15 20:41:03,014 [INFO] Found 8 posts in r/popular
2025-05-15 20:41:03,014 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 20:41:04,940 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 20:41:04,940 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 20:41:08,063 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 20:41:08,063 [INFO] Found 131 unique posts out of 134 total posts
2025-05-15 20:42:25,900 [INFO] Successfully processed 131 Reddit posts (0 inserted, 131 updated)
2025-05-15 20:51:04,481 [INFO] Starting Reddit scraping...
2025-05-15 20:51:04,482 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 20:51:04,482 [INFO] Successfully connected to Reddit API
2025-05-15 20:51:04,483 [INFO] Scraping subreddit: r/all
2025-05-15 20:51:06,656 [INFO] Found 6 posts in r/all
2025-05-15 20:51:06,656 [INFO] Scraping subreddit: r/popular
2025-05-15 20:51:08,580 [INFO] Found 10 posts in r/popular
2025-05-15 20:51:08,580 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 20:51:10,488 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 20:51:10,489 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 20:51:14,410 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 20:51:14,411 [INFO] Found 134 unique posts out of 137 total posts
2025-05-15 20:52:33,134 [INFO] Successfully processed 134 Reddit posts (2 inserted, 132 updated)
2025-05-15 20:58:07,828 [INFO] Starting Reddit scraping...
2025-05-15 20:58:07,828 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 20:58:07,829 [INFO] Successfully connected to Reddit API
2025-05-15 20:58:07,829 [INFO] Scraping subreddit: r/all
2025-05-15 20:58:09,836 [INFO] Found 5 posts in r/all
2025-05-15 20:58:09,837 [INFO] Scraping subreddit: r/popular
2025-05-15 20:58:11,469 [INFO] Found 12 posts in r/popular
2025-05-15 20:58:11,469 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 20:58:12,266 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 20:58:12,266 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 20:58:14,523 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 20:58:14,524 [INFO] Found 135 unique posts out of 138 total posts
2025-05-15 20:59:34,065 [INFO] Successfully processed 135 Reddit posts (1 inserted, 134 updated)
2025-05-15 21:07:56,239 [INFO] Starting Reddit scraping...
2025-05-15 21:07:56,239 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 21:07:56,240 [INFO] Successfully connected to Reddit API
2025-05-15 21:07:56,240 [INFO] Scraping subreddit: r/all
2025-05-15 21:07:57,770 [INFO] Found 3 posts in r/all
2025-05-15 21:07:57,771 [INFO] Scraping subreddit: r/popular
2025-05-15 21:07:59,201 [INFO] Found 11 posts in r/popular
2025-05-15 21:07:59,201 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 21:08:00,369 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 21:08:00,370 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 21:08:02,926 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 21:08:02,926 [INFO] Found 132 unique posts out of 135 total posts
2025-05-15 21:09:22,468 [INFO] Successfully processed 132 Reddit posts (0 inserted, 132 updated)
2025-05-15 21:15:29,135 [INFO] Starting Reddit scraping...
2025-05-15 21:15:29,135 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 21:15:29,136 [INFO] Successfully connected to Reddit API
2025-05-15 21:15:29,136 [INFO] Scraping subreddit: r/all
2025-05-15 21:15:31,572 [INFO] Found 3 posts in r/all
2025-05-15 21:15:31,572 [INFO] Scraping subreddit: r/popular
2025-05-15 21:15:33,812 [INFO] Found 9 posts in r/popular
2025-05-15 21:15:33,812 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 21:15:36,214 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 21:15:36,214 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 21:15:40,060 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 21:15:40,060 [INFO] Found 130 unique posts out of 133 total posts
2025-05-15 21:16:56,527 [INFO] Successfully processed 130 Reddit posts (0 inserted, 130 updated)
2025-05-15 21:24:45,477 [INFO] Starting Reddit scraping...
2025-05-15 21:24:45,477 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 21:24:45,478 [INFO] Successfully connected to Reddit API
2025-05-15 21:24:45,478 [INFO] Scraping subreddit: r/all
2025-05-15 21:24:47,473 [INFO] Found 2 posts in r/all
2025-05-15 21:24:47,474 [INFO] Scraping subreddit: r/popular
2025-05-15 21:24:48,773 [INFO] Found 10 posts in r/popular
2025-05-15 21:24:48,773 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 21:24:49,688 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 21:24:49,688 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 21:24:51,939 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 21:24:51,939 [INFO] Found 130 unique posts out of 133 total posts
2025-05-15 21:26:07,288 [INFO] Successfully processed 130 Reddit posts (0 inserted, 130 updated)
2025-05-15 21:33:17,823 [INFO] Starting Reddit scraping...
2025-05-15 21:33:17,824 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 21:33:17,825 [INFO] Successfully connected to Reddit API
2025-05-15 21:33:17,825 [INFO] Scraping subreddit: r/all
2025-05-15 21:33:19,392 [INFO] Found 2 posts in r/all
2025-05-15 21:33:19,393 [INFO] Scraping subreddit: r/popular
2025-05-15 21:33:20,722 [INFO] Found 11 posts in r/popular
2025-05-15 21:33:20,723 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 21:33:21,741 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 21:33:21,742 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 21:33:24,208 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 21:33:24,208 [INFO] Found 131 unique posts out of 134 total posts
2025-05-15 21:37:40,245 [INFO] Successfully processed 131 Reddit posts (1 inserted, 130 updated)
2025-05-15 21:42:17,121 [INFO] Starting Reddit scraping...
2025-05-15 21:42:17,122 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 21:42:17,123 [INFO] Successfully connected to Reddit API
2025-05-15 21:42:17,123 [INFO] Scraping subreddit: r/all
2025-05-15 21:42:18,890 [INFO] Found 2 posts in r/all
2025-05-15 21:42:18,890 [INFO] Scraping subreddit: r/popular
2025-05-15 21:42:20,155 [INFO] Found 10 posts in r/popular
2025-05-15 21:42:20,156 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 21:42:21,058 [INFO] Found 22 posts in r/trendingreddits
2025-05-15 21:42:21,058 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 21:42:23,093 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 21:42:23,093 [INFO] Found 131 unique posts out of 134 total posts
2025-05-15 21:43:11,054 [ERROR] Error processing post 1kna31f: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.
server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

2025-05-15 21:43:11,054 [ERROR] Database error: connection already closed
2025-05-15 21:43:11,055 [ERROR] Detailed error:
Traceback (most recent call last):
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\src\scheduler\jobs\reddit_scraper.py", line 174, in scrape_reddit
    inserted = 0
            ^^^^
    ...<22 lines>...
                post["score"],
    
psycopg2.OperationalError: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.
server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\src\scheduler\jobs\reddit_scraper.py", line 208, in scrape_reddit
    inserted += 1
    ^^^^^^^^^^^
psycopg2.InterfaceError: connection already closed
2025-05-15 22:01:57,350 [INFO] Starting Reddit scraping...
2025-05-15 22:01:57,350 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 22:01:57,351 [INFO] Successfully connected to Reddit API
2025-05-15 22:01:57,351 [INFO] Scraping subreddit: r/all
2025-05-15 22:01:58,907 [INFO] Found 2 posts in r/all
2025-05-15 22:01:58,908 [INFO] Scraping subreddit: r/popular
2025-05-15 22:02:00,304 [INFO] Found 10 posts in r/popular
2025-05-15 22:02:00,305 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 22:02:01,315 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 22:02:01,315 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 22:02:03,784 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 22:02:03,785 [INFO] Found 130 unique posts out of 133 total posts
2025-05-15 22:03:40,475 [ERROR] Error processing post 1kh3ajs: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.
server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

2025-05-15 22:03:40,476 [ERROR] Database error: connection already closed
2025-05-15 22:03:40,476 [ERROR] Detailed error:
Traceback (most recent call last):
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\src\scheduler\jobs\reddit_scraper.py", line 205, in scrape_reddit
    # Check if it was an insert or update
psycopg2.OperationalError: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.
server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\src\scheduler\jobs\reddit_scraper.py", line 208, in scrape_reddit
    inserted += 1
    ^^^^^^^^^^^
psycopg2.InterfaceError: connection already closed
2025-05-15 22:21:52,949 [INFO] Starting Reddit scraping...
2025-05-15 22:21:52,949 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 22:21:52,950 [INFO] Successfully connected to Reddit API
2025-05-15 22:21:52,950 [INFO] Scraping subreddit: r/all
2025-05-15 22:21:54,529 [INFO] Found 2 posts in r/all
2025-05-15 22:21:54,529 [INFO] Scraping subreddit: r/popular
2025-05-15 22:21:56,196 [INFO] Found 8 posts in r/popular
2025-05-15 22:21:56,197 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 22:21:57,101 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 22:21:57,102 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 22:21:59,818 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 22:21:59,819 [INFO] Found 128 unique posts out of 131 total posts
2025-05-15 22:22:47,286 [ERROR] Error processing post 1kh3ajs: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.
server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

2025-05-15 22:22:47,286 [ERROR] Database error: connection already closed
2025-05-15 22:22:47,286 [ERROR] Detailed error:
Traceback (most recent call last):
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\src\scheduler\jobs\reddit_scraper.py", line 174, in scrape_reddit
    inserted = 0
            ^^^^
    ...<22 lines>...
                post["score"],
    
psycopg2.OperationalError: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.
server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\SofiePischl\Documents\01_HdM\10_ML_OPS\TrendAnalyseSocialMedia\src\scheduler\jobs\reddit_scraper.py", line 208, in scrape_reddit
    inserted += 1
    ^^^^^^^^^^^
psycopg2.InterfaceError: connection already closed
2025-05-15 22:39:59,411 [INFO] Starting Reddit scraping...
2025-05-15 22:39:59,411 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 22:39:59,412 [INFO] Successfully connected to Reddit API
2025-05-15 22:39:59,412 [INFO] Scraping subreddit: r/all
2025-05-15 22:40:01,065 [INFO] Found 2 posts in r/all
2025-05-15 22:40:01,066 [INFO] Scraping subreddit: r/popular
2025-05-15 22:40:02,342 [INFO] Found 11 posts in r/popular
2025-05-15 22:40:02,343 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 22:40:03,953 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 22:40:03,953 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 22:40:06,932 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 22:40:06,933 [INFO] Found 131 unique posts out of 134 total posts
2025-05-15 22:41:23,740 [INFO] Successfully processed 131 Reddit posts (2 inserted, 129 updated)
2025-05-15 22:56:46,950 [INFO] Starting Reddit scraping...
2025-05-15 22:56:46,950 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 22:56:46,950 [INFO] Successfully connected to Reddit API
2025-05-15 22:56:46,951 [INFO] Scraping subreddit: r/all
2025-05-15 22:56:48,785 [INFO] Found 2 posts in r/all
2025-05-15 22:56:48,785 [INFO] Scraping subreddit: r/popular
2025-05-15 22:56:50,292 [INFO] Found 9 posts in r/popular
2025-05-15 22:56:50,292 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 22:56:51,564 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 22:56:51,565 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 22:56:54,125 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 22:56:54,126 [INFO] Found 129 unique posts out of 132 total posts
2025-05-15 22:58:11,881 [INFO] Successfully processed 129 Reddit posts (0 inserted, 129 updated)
2025-05-15 23:13:34,819 [INFO] Starting Reddit scraping...
2025-05-15 23:13:34,820 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 23:13:34,820 [INFO] Successfully connected to Reddit API
2025-05-15 23:13:34,821 [INFO] Scraping subreddit: r/all
2025-05-15 23:13:36,406 [INFO] Found 2 posts in r/all
2025-05-15 23:13:36,406 [INFO] Scraping subreddit: r/popular
2025-05-15 23:13:37,914 [INFO] Found 10 posts in r/popular
2025-05-15 23:13:37,915 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 23:13:38,847 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 23:13:38,848 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 23:13:41,057 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 23:13:41,058 [INFO] Found 130 unique posts out of 133 total posts
2025-05-15 23:14:58,250 [INFO] Successfully processed 130 Reddit posts (0 inserted, 130 updated)
2025-05-15 23:30:21,684 [INFO] Starting Reddit scraping...
2025-05-15 23:30:21,684 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 23:30:21,685 [INFO] Successfully connected to Reddit API
2025-05-15 23:30:21,685 [INFO] Scraping subreddit: r/all
2025-05-15 23:30:23,884 [INFO] Found 3 posts in r/all
2025-05-15 23:30:23,885 [INFO] Scraping subreddit: r/popular
2025-05-15 23:30:25,280 [INFO] Found 9 posts in r/popular
2025-05-15 23:30:25,280 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 23:30:26,202 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 23:30:26,203 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 23:30:28,730 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 23:30:28,730 [INFO] Found 130 unique posts out of 133 total posts
2025-05-15 23:31:46,248 [INFO] Successfully processed 130 Reddit posts (1 inserted, 129 updated)
2025-05-15 23:47:09,940 [INFO] Starting Reddit scraping...
2025-05-15 23:47:09,940 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 23:47:09,941 [INFO] Successfully connected to Reddit API
2025-05-15 23:47:09,941 [INFO] Scraping subreddit: r/all
2025-05-15 23:47:11,372 [INFO] Found 3 posts in r/all
2025-05-15 23:47:11,373 [INFO] Scraping subreddit: r/popular
2025-05-15 23:47:12,944 [INFO] Found 10 posts in r/popular
2025-05-15 23:47:12,945 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 23:47:13,883 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 23:47:13,884 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 23:47:16,686 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 23:47:16,686 [INFO] Found 131 unique posts out of 134 total posts
2025-05-15 23:48:32,392 [INFO] Successfully processed 131 Reddit posts (0 inserted, 131 updated)
2025-05-15 23:54:24,921 [INFO] Starting Reddit scraping...
2025-05-15 23:54:24,921 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-15 23:54:24,924 [INFO] Successfully connected to Reddit API
2025-05-15 23:54:24,924 [INFO] Scraping subreddit: r/all
2025-05-15 23:54:26,402 [INFO] Found 4 posts in r/all
2025-05-15 23:54:26,402 [INFO] Scraping subreddit: r/popular
2025-05-15 23:54:27,822 [INFO] Found 9 posts in r/popular
2025-05-15 23:54:27,823 [INFO] Scraping subreddit: r/trendingreddits
2025-05-15 23:54:28,749 [INFO] Found 21 posts in r/trendingreddits
2025-05-15 23:54:28,749 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-15 23:54:31,186 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-15 23:54:31,187 [INFO] Found 131 unique posts out of 134 total posts
2025-05-15 23:55:48,126 [INFO] Successfully processed 131 Reddit posts (1 inserted, 130 updated)
2025-05-16 05:14:09,575 [INFO] Starting Reddit scraping...
2025-05-16 05:14:09,575 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-16 05:14:09,576 [INFO] Successfully connected to Reddit API
2025-05-16 05:14:09,576 [INFO] Scraping subreddit: r/all
2025-05-16 05:14:09,769 [INFO] Starting Reddit scraping...
2025-05-16 05:14:09,769 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-16 05:14:09,770 [INFO] Successfully connected to Reddit API
2025-05-16 05:14:09,770 [INFO] Scraping subreddit: r/all
2025-05-16 05:14:11,022 [INFO] Found 4 posts in r/all
2025-05-16 05:14:11,023 [INFO] Scraping subreddit: r/popular
2025-05-16 05:14:11,643 [INFO] Found 4 posts in r/all
2025-05-16 05:14:11,643 [INFO] Scraping subreddit: r/popular
2025-05-16 05:14:12,221 [INFO] Found 13 posts in r/popular
2025-05-16 05:14:12,221 [INFO] Scraping subreddit: r/trendingreddits
2025-05-16 05:14:12,994 [INFO] Found 13 posts in r/popular
2025-05-16 05:14:12,995 [INFO] Scraping subreddit: r/trendingreddits
2025-05-16 05:14:13,082 [INFO] Found 21 posts in r/trendingreddits
2025-05-16 05:14:13,082 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-16 05:14:13,920 [INFO] Found 21 posts in r/trendingreddits
2025-05-16 05:14:13,920 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-16 05:14:15,519 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-16 05:14:15,519 [INFO] Found 135 unique posts out of 138 total posts
2025-05-16 05:14:16,226 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-16 05:14:16,227 [INFO] Found 135 unique posts out of 138 total posts
2025-05-16 05:15:51,453 [INFO] Successfully processed 135 Reddit posts (10 inserted, 125 updated)
2025-05-16 05:15:52,133 [INFO] Successfully processed 135 Reddit posts (0 inserted, 135 updated)
2025-05-16 08:18:17,728 [INFO] Starting Reddit scraping...
2025-05-16 08:18:17,729 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-16 08:18:17,729 [INFO] Successfully connected to Reddit API
2025-05-16 08:18:17,730 [INFO] Scraping subreddit: r/all
2025-05-16 08:18:19,717 [INFO] Found 7 posts in r/all
2025-05-16 08:18:19,718 [INFO] Scraping subreddit: r/popular
2025-05-16 08:18:21,229 [INFO] Found 15 posts in r/popular
2025-05-16 08:18:21,230 [INFO] Scraping subreddit: r/trendingreddits
2025-05-16 08:18:22,194 [INFO] Found 21 posts in r/trendingreddits
2025-05-16 08:18:22,194 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-16 08:18:24,367 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-16 08:18:24,368 [INFO] Found 140 unique posts out of 143 total posts
2025-05-16 08:20:06,923 [INFO] Successfully processed 140 Reddit posts (7 inserted, 133 updated)
2025-05-16 08:33:20,815 [INFO] Starting Reddit scraping...
2025-05-16 08:33:20,815 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-16 08:33:20,815 [INFO] Successfully connected to Reddit API
2025-05-16 08:33:20,815 [INFO] Scraping subreddit: r/all
2025-05-16 08:33:22,738 [INFO] Found 7 posts in r/all
2025-05-16 08:33:22,738 [INFO] Scraping subreddit: r/popular
2025-05-16 08:33:24,267 [INFO] Found 14 posts in r/popular
2025-05-16 08:33:24,267 [INFO] Scraping subreddit: r/trendingreddits
2025-05-16 08:33:25,208 [INFO] Found 21 posts in r/trendingreddits
2025-05-16 08:33:25,208 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-16 08:33:27,432 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-16 08:33:27,432 [INFO] Found 139 unique posts out of 142 total posts
2025-05-16 08:35:06,855 [INFO] Successfully processed 139 Reddit posts (0 inserted, 139 updated)
2025-05-16 08:35:35,992 [INFO] Starting Reddit scraping...
2025-05-16 08:35:35,993 [INFO] Connecting to Reddit API with ID: jl1Te...
2025-05-16 08:35:35,994 [INFO] Successfully connected to Reddit API
2025-05-16 08:35:35,994 [INFO] Scraping subreddit: r/all
2025-05-16 08:35:37,960 [INFO] Found 7 posts in r/all
2025-05-16 08:35:37,960 [INFO] Scraping subreddit: r/popular
2025-05-16 08:35:39,339 [INFO] Found 14 posts in r/popular
2025-05-16 08:35:39,339 [INFO] Scraping subreddit: r/trendingreddits
2025-05-16 08:35:40,327 [INFO] Found 21 posts in r/trendingreddits
2025-05-16 08:35:40,328 [INFO] Scraping subreddit: r/trendingsubreddits
2025-05-16 08:35:42,844 [INFO] Found 100 posts in r/trendingsubreddits
2025-05-16 08:35:42,844 [INFO] Found 139 unique posts out of 142 total posts
2025-05-16 08:37:20,037 [INFO] Successfully processed 139 Reddit posts (0 inserted, 139 updated)
