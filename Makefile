# --------------------------------------------
# ğŸ”§ ENV-VARIABLEN & BASISKONFIGURATION
# --------------------------------------------

include .env
export

API_URL=https://trendanalysesocialmedia.onrender.com
TOKEN=Bearer $(API_SECRET)

FILES=reddit_data.csv tiktok_data.csv youtube_data.csv
LOGS=reddit.log tiktok.log youtube.log

IMAGE_NAME=trendsage
CONTAINER_NAME=trend_scheduler
PORT=8080
CONTAINER_PORT=10000

# --------------------------------------------
# ğŸ“¡ REMOTE SCRAPING & DATEN-SYNC
# --------------------------------------------

.PHONY: sync trigger-api trigger-loop

# â±ï¸ Scraping-Job Ã¼ber API auf Render auslÃ¶sen + Daten/Logs lokal abholen
sync:
	curl -X POST $(API_URL)/run-scrapers \
		-H "Authorization: $(TOKEN)"

	@echo "\nâ¬‡ï¸  Lade Daten herunter & hÃ¤nge sie an bestehende Dateien an ..."
	@mkdir -p data/raw
	@for file in $(FILES); do \
		tmp="data/raw/tmp_$$file"; \
		curl -s $(API_URL)/data/download/$$file -H "Authorization: $(TOKEN)" -o $$tmp; \
		if [ -f data/raw/$$file ]; then \
			tail -n +2 $$tmp >> data/raw/$$file; \
		else \
			mv $$tmp data/raw/$$file; \
		fi; \
		rm -f $$tmp; \
	done

	@echo "\nâ¬‡ï¸  Lade Logs herunter & hÃ¤nge sie an bestehende Dateien an ..."
	@mkdir -p logs
	@for log in $(LOGS); do \
		tmp="logs/tmp_$$log"; \
		curl -s $(API_URL)/logs/download/$$log -H "Authorization: $(TOKEN)" -o $$tmp; \
		if [ -f logs/$$log ]; then \
			cat $$tmp >> logs/$$log; \
		else \
			mv $$tmp logs/$$log; \
		fi; \
		rm -f $$tmp; \
	done

	@echo "\nâœ… Alle Dateien synchronisiert."

# ğŸ” Nur Scraper via API triggern (z. B. fÃ¼r Testzwecke)
trigger-api:
	curl -X POST $(API_URL)/run-scrapers \
		-H "Authorization: $(TOKEN)"

# ğŸ•“ Lokal laufende Endlosschleife, die alle 15min Render abfragt & lokal scrapt
trigger-loop:
	podman run -it --rm \
		--env-file .env \
		-v $(PWD)/logs:/app/logs \
		-v $(PWD)/data:/app/data \
		-v $(PWD):/app \
		-w /app \
		$(IMAGE_NAME) \
		python src/scheduler/scraper_trigger.py

# --------------------------------------------
# ğŸ§± PODMAN CONTAINER-STEUERUNG
# --------------------------------------------

.PHONY: build run run-detached clean-container restart logs shell

# ğŸ“¦ Container-Image bauen
build:
	podman build -t $(IMAGE_NAME) .

# ğŸš€ Container interaktiv starten (API lokal aufrufbar)
run:
	podman run -p $(PORT):$(CONTAINER_PORT) \
		--name $(CONTAINER_NAME) \
		--env-file .env \
		-v $(PWD)/logs:/app/logs \
		-v $(PWD)/data:/app/data \
		-v $(PWD):/app \
		-w /app \
		$(IMAGE_NAME)

# ğŸ” Container im Hintergrund starten
run-detached:
	podman run -d -p $(PORT):$(CONTAINER_PORT) \
		--name $(CONTAINER_NAME) \
		--env-file .env \
		-v $(PWD)/logs:/app/logs \
		-v $(PWD)/data:/app/data \
		-v $(PWD):/app \
		-w /app \
		$(IMAGE_NAME)

# ğŸ§¼ Container stoppen und lÃ¶schen
clean-container:
	-podman stop $(CONTAINER_NAME)
	-podman rm $(CONTAINER_NAME)

# ğŸ§¨ Alles lÃ¶schen (inkl. lokale Logs & Daten)
clean-all: clean-container
	rm -rf logs/* data/*

# ğŸ”„ Container neustarten
restart:
	podman restart $(CONTAINER_NAME)

# ğŸ“‹ Live-Logs anzeigen
logs:
	podman logs -f $(CONTAINER_NAME)

# ğŸ” Interaktive Shell im Container Ã¶ffnen
shell:
	podman exec -it $(CONTAINER_NAME) /bin/sh

# --------------------------------------------
# âš™ï¸ SCRAPER LOKAL AUSFÃœHREN (zum Debuggen)
# --------------------------------------------

.PHONY: run-all-scrapers

run-all-scrapers:
	python src/scheduler/run_all_scrapers.py

# --------------------------------------------
# ğŸ³ OPTIONAL: DOCKER-COMPOSE UNTERSTÃœTZUNG
# --------------------------------------------

.PHONY: compose-up compose-logs

compose-up:
	docker-compose up --build

compose-logs:
	docker-compose logs -f scraper-trigger

# --------------------------------------------
# ğŸ› ï¸ ENTWICKLUNG & WARTUNG
# --------------------------------------------

.PHONY: install start qdrant stop-qdrant lint test pipeline download-nltk clean

# ğŸ“¦ AbhÃ¤ngigkeiten installieren
install:
	pip install -e .

# ğŸš€ FastAPI-Server starten
start:
	uvicorn src.main:app --reload

# ğŸ” Qdrant Vektordatenbank starten
qdrant:
	docker run -d --name qdrant -p 6333:6333 -p 6334:6334 qdrant/qdrant

# ğŸ›‘ Qdrant stoppen
stop-qdrant:
	docker stop qdrant || true
	docker rm qdrant || true

# âœ¨ Code formatieren und linten
lint:
	black src/ || true
	flake8 src/ || true

# ğŸ§ª Tests ausfÃ¼hren
test:
	pytest || echo "No tests found."

# ğŸ”„ Pipeline ausfÃ¼hren
pipeline:
	python src/setup_pipeline.py

# ğŸ“š NLTK-Ressourcen herunterladen
download-nltk:
	python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords'); nltk.download('wordnet'); nltk.download('averaged_perceptron_tagger'); nltk.download('averaged_perceptron_tagger_eng')"

# ğŸ§¹ TemporÃ¤re Dateien aufrÃ¤umen
clean:
	rm -rf __pycache__ .pytest_cache .mypy_cache
	rm -rf data/processed/*.csv data/processed/*.json
	rm -rf .venv
	echo "Cleaned up temporary and output files."
