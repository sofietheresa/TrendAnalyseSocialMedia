name: Scrape & Pull Data

on:
  schedule:
    - cron: "*/15 * * * *" # alle 15 Minuten
  workflow_dispatch: # manuell starten mÃ¶glich

jobs:
  scrape-and-pull:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repo
        uses: actions/checkout@v3

      - name: Trigger Scraper on Render
        run: |
          curl -X POST https://trendanalysesocialmedia.onrender.com/run-scrapers \
            -H "Authorization: Bearer ${{ secrets.API_SECRET }}"

      - name: Download Scraped Data
        run: |
          mkdir -p data/raw logs

          for file in reddit_data.csv youtube_data.csv tiktok_data.csv; do
            curl -sS "https://trendanalysesocialmedia.onrender.com/data/download/$file" \
              -H "Authorization: Bearer ${{ secrets.API_SECRET }}" \
              -o "data/raw/$file"
          done

          for log in reddit.log youtube.log tiktok.log; do
            curl -sS "https://trendanalysesocialmedia.onrender.com/logs/download/$log" \
              -H "Authorization: Bearer ${{ secrets.API_SECRET }}" \
              -o "logs/$log"
          done

      - name: Commit & Push Data
        run: |
          git config user.name "github-actions"
          git config user.email "actions@github.com"
          git add data/raw/*.csv logs/*.log
          git commit -m "ðŸ“Š Scraped data @ $(date -u +"%Y-%m-%d %H:%M:%S")" || echo "No changes"
          git push
