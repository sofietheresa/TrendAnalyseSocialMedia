Danke f√ºr die Erg√§nzungen. Auf dieser Grundlage habe ich den Erfahrungsbericht nun etwas f√∂rmlicher, koh√§renter und trotzdem pers√∂nlich gehalten. Er ist gut geeignet f√ºr eine Projektdokumentation oder einen schriftlichen Anhang im Rahmen einer Abgabe:

---

## üìò Erfahrungsbericht zum Projekt: Social-Media-Datenanalyse mit MLOps-Integration

### Einleitung

Mein Projekt startete offiziell am 11. April 2025 ‚Äì also vor exakt 30 Tagen. Der Einstieg gestaltete sich jedoch schwieriger als erwartet, da ich zun√§chst mit einem anderen Thema begonnen hatte. Erst nach mehreren Umorientierungen und viel Unsicherheit entschied ich mich f√ºr die Analyse von Social-Media-Daten ‚Äì mit dem Schwerpunkt auf automatisierter Datengewinnung, Vorverarbeitung und maschinellem Lernen innerhalb einer produktionsreifen MLOps-Architektur.

Die vergangenen zehn Tage waren besonders intensiv. Mit wachsendem Zeitdruck konnte ich in kurzer Zeit gro√üe Fortschritte erzielen, auch wenn viele H√ºrden auf dem Weg lagen. Zwischenzeitlich war ich verzweifelt, doch am Ende steht ein funktionierendes System ‚Äì mit Optimierungspotenzial, aber klarer Struktur und ausbauf√§higer Funktionalit√§t.

---

### Thematische Ausrichtung und Zielsetzung

Ziel meines Projekts war es, Beitr√§ge aus sozialen Netzwerken wie Instagram, TikTok und Reddit automatisiert zu erfassen und hinsichtlich Stimmung, Themen und potenzieller Relevanz zu analysieren. Ich wollte herausfinden, wie sich Inhalte typisieren und Stimmungen in Texten quantifizieren lassen ‚Äì und gleichzeitig herausfordernde Aspekte wie Datenzugriff, Deployment und Wiederholbarkeit sauber l√∂sen.

---

### Datenbeschaffung: Vom Experiment zur Infrastruktur

Der wohl aufwendigste und nervenaufreibendste Teil des Projekts war das Webscraping. Ich hatte zun√§chst vor, Instagram und die Plattform X (ehemals Twitter) gemeinsam zu verarbeiten, musste jedoch aufgrund unzuverl√§ssiger Schnittstellen und technischer Einschr√§nkungen letztere streichen.

F√ºr Instagram nutzte ich verschiedene Python-Bibliotheken, darunter `instaloader`, `instascrape` und `instagram-scraper`, stie√ü jedoch schnell an deren Grenzen (Rate-Limits, fehlender Login-Support, etc.). Die letztlich funktionierende L√∂sung war ein automatisierter Browserzugriff mittels Selenium ‚Äì technisch aufwendig, aber zuverl√§ssig genug f√ºr ein erstes Datenkorpus.

Ich legte fr√ºh fest, welche Informationen ich speichern wollte ‚Äì darunter URL, Ver√∂ffentlichungsdatum, ALT-Text, Benutzername, Bildunterschrift und (wenn m√∂glich) die Anzahl der Likes. Die Datenstruktur wurde mehrfach angepasst und erst sp√§t in eine relationale Datenbank √ºberf√ºhrt. Bis dahin arbeitete ich ausschlie√ülich mit CSV-Dateien, was bei paralleler Entwicklung und Versionskontrolle zu zahlreichen Merge-Konflikten f√ºhrte.

---

### Architektur & Deployment: Container, Scheduler und hybride Systeme

Ein zentrales Ziel war es, das Projekt modular und containerisiert umzusetzen. Ich setzte konsequent auf Docker, um alle Komponenten sauber zu kapseln. F√ºr das Hosting und Scheduling verwendete ich Render sowie GitHub Actions. Doch auch hier traten unerwartete Probleme auf: TikTok lie√ü sich innerhalb des Containers nicht zuverl√§ssig scrapen, weshalb ich auf eine hybride L√∂sung mit meinem lokalen Rechner als Datenerfassungseinheit ausweichen musste.

Render stellte sich zudem als ressourcenintensiv heraus ‚Äì das Starten der App dauerte ungew√∂hnlich lange. Auch das Scheduling √ºber den Windows Task Scheduler scheiterte, u.‚ÄØa. an Sicherheitsrichtlinien des Betriebssystems (Stichwort: IBM Security). Trotz alledem gelang es mir, eine funktionierende Architektur zu etablieren, in der Daten gesammelt, verarbeitet und ausgewertet werden konnten.

---

### Modellierung & Analyse: Zwischen Experiment und Pipeline

Die eigentliche Modellierung r√ºckte lange in den Hintergrund. Erst als die Datenbeschaffung weitgehend funktionierte, begann ich mit der Umsetzung von Analyse- und Vorhersagemodellen. Zum Einsatz kamen:

- **Feature-Engineering** mit TF-IDF
- **Regression** √ºber Random Forest zur Bewertung von Popularit√§t
- **Topic Modeling** mittels LDA und BERTopic
- **Sentimentanalyse** mit TextBlob, VADER und einem Transformer-Modell

Zur Evaluation nutzte ich Metriken wie MSE, MAE, R¬≤, Explained Variance und weitere. Die Vorhersagen selbst sind aktuell noch wenig aussagekr√§ftig, was ich auf die Heterogenit√§t und begrenzte Gr√∂√üe der Datens√§tze zur√ºckf√ºhre. Hier besteht noch Optimierungsbedarf.

Die gesamte Modellpipeline wurde mit **ZenML** orchestriert. Ich definierte sowohl Preprocessing- als auch Training- und Inferenzschritte in wiederverwendbaren Pipelines. F√ºr Visualisierung und Interaktion baute ich ein **Streamlit-Dashboard**, √ºber das sich unter anderem die Pipelines starten lassen.

---

### Reflexion & Ausblick

Dieses Projekt war f√ºr mich ein Wechselbad der Gef√ºhle. √úber Wochen hinweg k√§mpfte ich mit instabilen Schnittstellen, fehlerhaften Abh√§ngigkeiten, Deployment-Problemen und einer steilen Lernkurve im Bereich MLOps. Die letzten zehn Tage waren gepr√§gt von hoher Intensit√§t, aber auch von einer klaren Struktur und sichtbaren Fortschritten.

Die wichtigsten Learnings:

- **Scraping ist nie trivial**, insbesondere bei Plattformen ohne stabile √∂ffentliche APIs.
- **Containerisierung hilft**, aber bringt auch neue Herausforderungen.
- **MLOps ist mehr als Deployment** ‚Äì es beginnt mit Datenverf√ºgbarkeit, Monitoring, Automatisierung und endet erst bei nachvollziehbarer Evaluation.
- **Alleine arbeiten hei√üt alles selbst entscheiden m√ºssen** ‚Äì das ist einerseits befreiend, andererseits fordernd.

F√ºr die verbleibende Projektzeit plane ich, die Modellg√ºte zu verbessern, das Dashboard interaktiver zu gestalten und den √úbergang von Entwicklung zu Betrieb noch klarer zu strukturieren.
