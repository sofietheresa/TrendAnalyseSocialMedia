## üìò Erfahrungsbericht zum Projekt: Social-Media-Datenanalyse mit MLOps-Integration

Nat√ºrlich ‚Äì hier ist dein √ºberarbeiteter Text in einer klareren, professionelleren und stilistisch runderen Fassung. Ich habe dabei sowohl den Ton als auch den Aufbau leicht angepasst, ohne deinen pers√∂nlichen Stil zu verlieren:


### Einleitung

Mein Projekt begann offiziell am 13. M√§rz 2025. Der Einstieg war herausfordernd: Ich war zun√§chst unentschlossen, welches Thema ich verfolgen sollte. Wichtig war mir, ein Vorhaben zu w√§hlen, das sowohl pers√∂nliches Interesse weckt als auch gesellschaftliche Relevanz besitzt ‚Äì abseits der g√§ngigen Standardprojekte.

Urspr√ºnglich plante ich eine Analyse von Symptomen im Bereich neurodivergenter Erkrankungen. Dieses Thema h√§tte zwar gro√ües Potenzial geboten, erwies sich jedoch aufgrund unzureichender √∂ffentlich zug√§nglicher Datenquellen als kaum umsetzbar. In Absprache mit Prof. Dr. Klotz orientierte ich mich daher neu ‚Äì hin zu einer datengetriebenen Analyse von Trends auf sozialen Medien.

Ab diesem Zeitpunkt nahm das Projekt konkrete Formen an, allerdings war bereits wertvolle Zeit vergangen. Um den Projektverlauf besser einordnen zu k√∂nnen, folgt eine grobe zeitliche Einordnung:

#### Zeit√ºbersicht

| Zeitraum        | Schwerpunkt                                            |
| --------------- | ------------------------------------------------------ |
| 17.03. ‚Äì 23.03. | Beruflicher Fokus, kein Fortschritt am Projekt         |
| 24.03. ‚Äì 30.03. | Beruflicher Fokus, kein Fortschritt am Projekt         |
| 31.03. ‚Äì 06.04. | Themenfindung                                          |
| 07.04. ‚Äì 13.04. | Umorientierung auf Social-Media-Trendanalyse           |
| 14.04. ‚Äì 20.04. | Erste Scraping-Skripte, Test verschiedener Plattformen |
| 21.04. ‚Äì 27.04. | Versuch der Automatisierung mit Render                 |
| 28.04. ‚Äì 04.05. | Fehlerbehebung bei automatisiertem Scraping\*          |
| 05.05. ‚Äì 11.05. | Daten sammeln, bereinigen und zusammenf√ºhren           |
| 12.05. ‚Äì 17.05. | Modellierung, Evaluierung, Dokumentation               |

\* Das Scraping lief zu diesem Zeitpunkt lokal bereits stabil. Nach dem Deployment auf Render zeigte sich jedoch, dass der TikTok-Scraper dort nicht mehr funktionierte ‚Äì vermutlich wegen der Architektur der inoffiziellen API. Daher entschied ich mich f√ºr eine hybride L√∂sung mit lokalem Scraper und serverseitiger Verarbeitung.

Diese √úbersicht verdeutlicht, wie stark der Erfolg des Projekts von einer stabilen Datenbasis abh√§ngig war ‚Äì und wie viel Zeit f√ºr deren Aufbau erforderlich war. Die kontinuierliche Anpassung des Scraping-Prozesses war dabei die gr√∂√üte Herausforderung: Immer wieder musste ich Teile der Architektur √ºberarbeiten oder zur√ºckrollen, wodurch auch Inkonsistenzen in der Datenstruktur entstanden.



### Thematische Ausrichtung und Zielsetzung

Ziel meines Projekts war es, Beitr√§ge aus sozialen Netzwerken wie TikTok, Reddit und YouTube automatisiert zu erfassen, zu bereinigen und hinsichtlich Stimmung, thematischer Einordnung und m√∂glicher Popularit√§t zu analysieren. Dabei sollte nicht nur ein Modell trainiert werden, sondern ein vollst√§ndiger, reproduzierbarer Analyseprozess entstehen ‚Äì von der Datenbeschaffung √ºber das Feature Engineering bis hin zur Deployment-f√§higen Architektur.

Der Fokus lag somit auf einem Ende-zu-Ende-Ansatz im Sinne moderner MLOps: Automatisierung, Wiederverwendbarkeit und Modularisierung standen im Vordergrund, ohne dabei die inhaltliche Aussagekraft der Analysen aus dem Blick zu verlieren.


### Datenbeschaffung: Plattformlogik, Instabilit√§t und Vereinheitlichung

Die Datenbeschaffung stellte sich als der technisch wie organisatorisch aufwendigste Teil des Projekts heraus. Die beteiligten Plattformen ‚Äì Reddit, Instagram, X (ehemals Twitter), TikTok und YouTube ‚Äì erforderten jeweils eigene Strategien, Scraping-Logik oder die Nutzung (inoffizieller) APIs. F√ºr nahezu jede Quelle waren mehrere Versuche notwendig, bis eine stabile Datengewinnung m√∂glich war.

Ich begann mit Reddit, da hier eine gut dokumentierte und stabile API zur Verf√ºgung steht. Trotz dieser vergleichsweise g√ºnstigen Voraussetzungen ben√∂tigte ich einige Zeit, um ein robustes Scraping-Skript zu entwickeln, das regelm√§√üig und zuverl√§ssig Daten erfassen konnte.

Deutlich komplizierter gestaltete sich die Arbeit mit Instagram. Meta stellt keine √∂ffentliche API zur Verf√ºgung, wodurch viele g√§ngige Python-Bibliotheken (z.‚ÄØB. `instaloader`, `instascrape`) schnell an technische oder rechtliche Grenzen stie√üen. Die einzig halbwegs funktionierende L√∂sung bestand darin, mit Selenium einen manuellen Nutzerzugriff zu simulieren: Ich legte einen neuen Account an, loggte mich automatisiert ein und sammelte Beitr√§ge √ºber die ‚ÄûExplore‚Äú-Seite. Dabei wurden zun√§chst nur rudiment√§re Informationen abgerufen; Details wie Likes, Captions oder Benutzernamen sollten nachtr√§glich √ºber XPath extrahiert werden. Allerdings stellte sich heraus, dass Instagram seine Seitenstruktur h√§ufig √§ndert, was den Ansatz sehr instabil machte. Aufgrund dieser Unsicherheit entschied ich mich, die Arbeit an Instagram-Daten zun√§chst zur√ºckzustellen.

Auch beim Versuch, Daten von X (ehemals Twitter) zu extrahieren, war ich nicht erfolgreich. Mehrere Bibliotheken und manuelle Versuche scheiterten ‚Äì nach weiterer Recherche stellte sich heraus, dass die Schnittstelle nur wenige Tage vor Projektbeginn vollst√§ndig abgeschaltet wurde. Damit war auch diese Datenquelle nicht weiter verfolgbar.

TikTok erwies sich als unerwartet zuverl√§ssig, wenn auch nicht problemlos. Nach dem Test mehrerer Bibliotheken fand ich eine inoffizielle API-L√∂sung, mit der sich Beitr√§ge stabil abrufen lie√üen ‚Äì inklusive wichtiger Metriken wie Likes, Shares, Kommentare und Plays.

Zuletzt erg√§nzte ich YouTube als Datenquelle. Der Zugriff √ºber die offizielle YouTube-API war unkompliziert. Allerdings stellte sich sp√§ter heraus, dass mein Skript wiederholt dieselben Beitr√§ge von der Explore-Seite erfasste. Anfangs schien der Import erfolgreich (‚Äû50 Eintr√§ge hinzugef√ºgt‚Äú), tats√§chlich handelte es sich jedoch oft um Duplikate. Auch diese Herausforderung musste nachtr√§glich durch entsprechende Filterung gel√∂st werden.

#### Automatisierung und Infrastruktur

Ein Ziel war es, das Scraping zu automatisieren, um √ºber l√§ngere Zeitr√§ume einen belastbaren Datensatz aufzubauen. Der erste Ansatz ‚Äì ein dauerhaft laufendes Python-Skript ‚Äì erwies sich als instabil. Auch die Nutzung des Windows Task Schedulers scheiterte auf meinem Arbeitslaptop, da sicherheitsrelevante Einschr√§nkungen (IBM Security) den geplanten Zugriff blockierten.

Ich versuchte daraufhin, die Infrastruktur vollst√§ndig zu deployen ‚Äì u.‚ÄØa. √ºber Render, Replit und Kubernetes (Minikube, Kind). Doch keine der L√∂sungen war in der Lage, das TikTok-Scraping zuverl√§ssig auszuf√ºhren. Die betreffende API funktionierte ausschlie√ülich lokal. Deshalb entschied ich mich f√ºr eine hybride Architektur: Das Backend lief online, das TikTok-Scraping wurde regelm√§√üig lokal durchgef√ºhrt und per API an den Server synchronisiert.

#### Vereinheitlichung der Daten

Die Konsolidierung der Daten aus den verschiedenen Plattformen stellte eine weitere Herausforderung dar. Zwischenzeitlich hatte ich Spaltennamen und Strukturen ver√§ndert ‚Äì teilweise sogar mehrfach. Einige Felder waren plattformspezifisch, andere sollten standardisiert zusammengef√ºhrt werden. Dies erforderte nicht nur sorgf√§ltige Mappings, sondern auch eine Normalisierung von Datentypen, Zeitformaten und Bezeichnern. Die Migration von CSV-Dateien in eine relationale SQLite-Datenbank erleichterte diesen Prozess erheblich, erforderte jedoch umfassende Nacharbeiten.



### Arbeiten auf zwei Ger√§ten

Im Verlauf des Projekts arbeitete ich abwechselnd auf zwei Systemen: einem privaten MacBook und einem Windows-basierten Arbeitslaptop. Diese duale Infrastruktur brachte einige technische Herausforderungen mit sich ‚Äì insbesondere beim Umgang mit Git (z.‚ÄØB. Konflikte durch unterschiedliche Zeilenendungen, Dateipfade oder Python-Umgebungen).

Trotz dieser Reibungspunkte stellte sich die parallele Entwicklung auf beiden Plattformen im Nachhinein als vorteilhaft heraus: Die Anwendung ist inzwischen plattform√ºbergreifend funktionsf√§hig ‚Äì sowohl unter macOS als auch unter Windows. Dies erh√∂ht nicht nur die Robustheit des Projekts, sondern schafft zugleich eine gr√∂√üere Einsatzflexibilit√§t im praktischen Umfeld.



###  Architektur & Deployment: Komplexit√§t sichtbar machen

Ein zentrales Ziel dieses Projekts war es, eine produktionsnahe, plattformunabh√§ngige Infrastruktur f√ºr automatisierte Machine-Learning-Pipelines zu entwickeln ‚Äì unter Verzicht auf Docker Desktop. Ich setzte konsequent auf **Podman** zur Containerisierung, orchestrierte alle Schritte mit **ZenML** und integrierte Backend (FastAPI), Frontend (Streamlit), Embedding-Index (Qdrant) und Datenbank (SQLite).

#### Urspr√ºngliche Architekturidee

Mein urspr√ºnglicher Plan sah den Einsatz von **Kubeflow Pipelines** auf einem lokalen Kubernetes-Cluster vor. Auf meinem macOS-System testete ich:

* **Minikube mit Podman:** Der API-Server (`localhost:8443`) lie√ü sich nicht starten, Add-ons wie `storage-provisioner` schlugen fehl, `kubectl get nodes` war nicht verf√ºgbar (EOF-Fehler).
* **Kubeflow Deployment:** Zwar lie√üen sich die YAML-Ressourcen anwenden, doch blieben die Pods im Status `ContainerCreating`. Port-Forwarding und UI-Aufruf scheiterten regelm√§√üig.

Ein paralleler Test auf Windows mit `kind` brachte ebenfalls keine stabile Umgebung hervor ‚Äì ein Muster zeichnete sich ab: **Kubeflow ist lokal ohne Docker Desktop nur schwer zuverl√§ssig nutzbar.**

#### Weitere Alternativen und Einschr√§nkungen

* **Render** funktionierte nicht stabil mit Qdrant oder automatisiertem Scraping.
* **Replit** konnte keine zuverl√§ssige SQLite-Verbindung halten.
*  Auch **kind** und **Bare-Metal-Kubernetes** waren nicht mit meinem Podman, SQLite FastAPI Setup praktikabel.
* Die TikTok-Schnittstelle blockierte externe Serveranfragen, weshalb ein lokales Scraping n√∂tig blieb.

#### Letztlich gew√§hlte L√∂sung

Ich entschied mich f√ºr eine **hybride Architektur**:

* Daten werden **lokal gescraped**, insbesondere TikTok.
* Die ML-Pipelines laufen containerisiert und orchestriert mit **ZenML**.
* Das System ist √ºber einen **Cloudflare Tunnel** erreichbar.
* FastAPI dient als Schnittstelle zur API, das Frontend l√§uft via Streamlit.

Diese pragmatische L√∂sung ist nicht vollst√§ndig cloudbasiert, aber in sich stabil und gut dokumentierbar ‚Äì und erf√ºllt damit die Anforderungen an ein prototypisches MLOps-System.



###  Modellierung & Analyse: Von der Theorie zur Anwendung

Die eigentliche Analyse erfolgte in einem separaten ZenML-Notebook mit Fokus auf **Textklassifikation, Zeitreihenanalyse und Sentimentauswertung**. Dabei kamen folgende Verfahren zum Einsatz:

* **BERTopic** zur Topic-Zuordnung √ºber Zeit
* **VADER** und **RoBERTa** zur Sentimentanalyse (regelbasiert + transformerbasiert)
* **TF-IDF & LDA** f√ºr klassische thematische Clusterbildung
* **Prophet** zur Prognose der Topic-Entwicklung √ºber Zeit
* **Random Forest & Logistic Regression** zur Popularit√§tsklassifikation

Das Notebook wurde mehrfach √ºberarbeitet und modularisiert. Fehlerquellen wie fehlerhafte Timestamps (`topics_over_time`) oder Performance-Probleme beim RoBERTa-Batchprocessing wurden gezielt behoben. Neue Visualisierungen (absolute/relative Topic-Anteile, Heatmaps) und Sentiment-Korrelationen runden die explorative Analyse ab.


###  Fazit & Ausblick

**Dieses Projekt war ein Lehrst√ºck in moderner ML-Systementwicklung.** Die Herausforderungen lagen nicht in der Modellierung allein, sondern in der Kombination aus Datenbeschaffung, Stabilit√§t, Plattformunabh√§ngigkeit und Reproduzierbarkeit. Durch die Umstellung auf ZenML, lokale Containerisierung mit Podman und die Entscheidung f√ºr eine hybride Architektur wurde ein System realisiert, das modular, erweiterbar und nachvollziehbar ist.

**Wichtige Erkenntnisse:**

* **Deployment ist oft schwieriger als Modelltraining.**
* **Plattformunabh√§ngigkeit ist erreichbar, aber kostet Zeit.**
* **Kubeflow ist m√§chtig, aber (noch) nicht ideal f√ºr lokale Entwickler-Setups ohne Docker Desktop.**
* **ZenML** bietet eine einfache, produktionsnahe Alternative ‚Äì besonders in fr√ºhen Projektphasen.
* **RoBERTa, BERTopic, Prophet** & Co. liefern interessante Einsichten ‚Äì vorausgesetzt, die Datenbasis ist stabil.

**N√§chste Schritte:**

* Aufbau eines stabilen Deployment-Ziels (ggf. ZenML + Cloud)
* Interaktive Visualisierung im Streamlit-Frontend verbessern
* Erweiterung um Live-Monitoring, Feedback-Loop und Model-Feedback durch Nutzer
